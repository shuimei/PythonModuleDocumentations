
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pyod.models package &#8212; pyod 0.5.6 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pyod.utils package" href="pyod.utils.html" />
    <link rel="prev" title="API Reference" href="pyod.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pyod.utils.html" title="pyod.utils package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="pyod.html" title="API Reference"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pyod 0.5.6 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pyod.html" accesskey="U">API Reference</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pyod-models-package">
<h1>pyod.models package<a class="headerlink" href="#pyod-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pyod.models.abod">
<span id="pyod-models-abod-module"></span><h2>pyod.models.abod module<a class="headerlink" href="#module-pyod.models.abod" title="Permalink to this headline">¶</a></h2>
<p>Angle-based Outlier Detector (ABOD)</p>
<dl class="class">
<dt id="pyod.models.abod.ABOD">
<em class="property">class </em><code class="descclassname">pyod.models.abod.</code><code class="descname">ABOD</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>n_neighbors=5</em>, <em>method='fast'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.abod.ABOD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>ABOD class for Angle-base Outlier Detection.
For an observation, the variance of its weighted cosine scores to all
neighbors could be viewed as the outlying score.
See <a class="reference internal" href="#kriegel2008angle" id="id1">[BKZ+08]</a> for details.</p>
<p>Two version of ABOD are supported:
Fast ABOD: use k nearest neighbors to approximate for complexity reduction
Original ABOD: consider all training points with high time complexity at
O(n^3).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Number of neighbors to use by default
for k neighbors queries.</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>{‘fast’, ‘default’}</p>
<ul>
<li>’fast’: fast ABOD. Only consider n_neighbors of training points</li>
<li>’default’: original ABOD with all training points, which could be
slow</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.abod.ABOD.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.abod.ABOD.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.abod.ABOD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id2">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.abod.ABOD.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.abod.ABOD.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.base">
<span id="pyod-models-base-module"></span><h2>pyod.models.base module<a class="headerlink" href="#module-pyod.models.base" title="Permalink to this headline">¶</a></h2>
<p>Base class for all outlier detector models</p>
<dl class="class">
<dt id="pyod.models.base.BaseDetector">
<em class="property">class </em><code class="descclassname">pyod.models.base.</code><code class="descname">BaseDetector</code><span class="sig-paren">(</span><em>contamination=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Abstract class for all outlier detection algorithms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.base.BaseDetector.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.fit_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.fit_predict_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id3">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.base.BaseDetector.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/base.html#BaseDetector.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.base.BaseDetector.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.cblof">
<span id="pyod-models-cblof-module"></span><h2>pyod.models.cblof module<a class="headerlink" href="#module-pyod.models.cblof" title="Permalink to this headline">¶</a></h2>
<p>Clustering Based Local Outlier Factor (CBLOF)</p>
<dl class="class">
<dt id="pyod.models.cblof.CBLOF">
<em class="property">class </em><code class="descclassname">pyod.models.cblof.</code><code class="descname">CBLOF</code><span class="sig-paren">(</span><em>n_clusters=8</em>, <em>contamination=0.1</em>, <em>clustering_estimator=None</em>, <em>alpha=0.9</em>, <em>beta=5</em>, <em>use_weights=False</em>, <em>check_estimator=True</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.cblof.CBLOF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>The CBLOF operator calculates the outlier score based on cluster-based
local outlier factor.</p>
<p>CBLOF takes as an input the data set and the cluster model that was
generated by a clustering algorithm. It classifies the clusters into small
clusters and large clusters using the parameters alpha and beta.
The anomaly score is then calculated based on the size of the cluster the
point belongs to as well as the distance to the nearest large cluster.</p>
<p>Use weighting for outlier factor based on the sizes of the clusters as
proposed in the original publication. Since this might lead to unexpected
behavior (outliers close to small clusters are not found), it is disabled
by default.Outliers scores are solely computed based on their distance to
the closest large cluster center.</p>
<p>By default, MiniBatchKMeans is used for clustering algorithm instead of
Squeezer algorithm mentioned in the original paper for multiple reasons.</p>
<p>See <a class="reference internal" href="#he2003discovering" id="id4">[BHXD03]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=8</em><em>)</em>) – The number of clusters to form as well as the number of
centroids to generate.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>clustering_estimator</strong> (<em>Estimator</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – <p>The base clustering algorithm for performing
data clustering. A valid clustering algorithm should be passed in.
The estimator should have standard sklearn APIs, fit() and predict().
The estimator should have attributes labels_ and cluster_centers_.
If cluster_centers_ is not in the attributes once the model is fit, it
is calculated as the mean of the samples in a cluster.</p>
<p>If not set, CBLOF uses MiniBatchKMeans for scalability. See
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html</a></p>
</li>
<li><strong>alpha</strong> (<em>float in</em><em> (</em><em>0.5</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – Coefficient for deciding small and large clusters. The ratio
of the number of samples in large clusters to the number of samples in
small clusters.</li>
<li><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>float in</em><em> (</em><em>1</em><em>,</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em><em></em>) – Coefficient for deciding small and large clusters. For a list
sorted clusters by size <cite>|C1|, |C2|, …, |Cn|, beta = |Ck|/|Ck-1|</cite></li>
<li><strong>use_weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If set to True, the size of clusters are used as
weights in outlier score calculation.</li>
<li><strong>check_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If set to True, check whether the base estimator
is consistent with sklearn standard</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>clustering_estimator_</strong> (<em>Estimator</em>) – Base estimator for clustering.</li>
<li><strong>cluster_labels_</strong> (<em>list of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Cluster assignment for the training samples</li>
<li><strong>cluster_sizes_</strong> (<em>list of shape</em><em> (</em><em>n_clusters</em><em>,</em><em>)</em>) – The size of each cluster once fitted with the
training data</li>
<li><strong>cluster_centers_</strong> (<em>numpy array of shape</em><em> (</em><em>n_clusters</em><em>, </em><em>n_features</em><em>)</em>) – The center of each cluster.</li>
<li><strong>small_cluster_labels_</strong> (<em>list of clusters numbers</em>) – The cluster assignments belonging to small
clusters</li>
<li><strong>large_cluster_labels_</strong> (<em>list of clusters numbers</em>) – The cluster assignments belonging to large
clusters</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.cblof.CBLOF.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.cblof.CBLOF.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.cblof.CBLOF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id5">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.cblof.CBLOF.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.cblof.CBLOF.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.combination">
<span id="pyod-models-combination-module"></span><h2>pyod.models.combination module<a class="headerlink" href="#module-pyod.models.combination" title="Permalink to this headline">¶</a></h2>
<p>A collection of model combination functionalities.</p>
<dl class="function">
<dt id="pyod.models.combination.aom">
<code class="descclassname">pyod.models.combination.</code><code class="descname">aom</code><span class="sig-paren">(</span><em>scores</em>, <em>n_buckets=5</em>, <em>method='static'</em>, <em>bootstrap_estimators=False</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#aom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.combination.aom" title="Permalink to this definition">¶</a></dt>
<dd><p>Average of Maximum - An ensemble method for combining multiple
estimators. See <a class="reference internal" href="#aggarwal2015theoretical" id="id6">[BAS15]</a> for details.</p>
<p>First dividing estimators into subgroups, take the maximum score as the
subgroup score. Finally, take the average of all subgroup outlier scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – The score matrix outputted from various estimators</li>
<li><strong>n_buckets</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – The number of subgroups to build</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='static'</em><em>)</em>) – {‘static’, ‘dynamic’}, if ‘dynamic’, build subgroups
randomly with dynamic bucket size.</li>
<li><strong>bootstrap_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether estimators are drawn with replacement.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The combined outlier scores.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Numpy array of shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.combination.average">
<code class="descclassname">pyod.models.combination.</code><code class="descname">average</code><span class="sig-paren">(</span><em>scores</em>, <em>estimator_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#average"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.combination.average" title="Permalink to this definition">¶</a></dt>
<dd><p>Combine the outlier scores from multiple estimators by averaging</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – score matrix from multiple estimators on the same samples</li>
<li><strong>estimator_weight</strong> (<em>list of shape</em><em> (</em><em>1</em><em>, </em><em>n_estimators</em><em>)</em>) – if specified, using weighted average</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the combined outlier scores</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy array of shape (n_samples, )</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.combination.maximization">
<code class="descclassname">pyod.models.combination.</code><code class="descname">maximization</code><span class="sig-paren">(</span><em>scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#maximization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.combination.maximization" title="Permalink to this definition">¶</a></dt>
<dd><p>Combine the outlier scores from multiple estimators by taking the maximum</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – score matrix from multiple estimators on the same samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">the combined outlier scores</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy array of shape (n_samples, )</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.combination.moa">
<code class="descclassname">pyod.models.combination.</code><code class="descname">moa</code><span class="sig-paren">(</span><em>scores</em>, <em>n_buckets=5</em>, <em>method='static'</em>, <em>bootstrap_estimators=False</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#moa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.combination.moa" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximization of Average - An ensemble method for combining multiple
estimators. See <a class="reference internal" href="#aggarwal2015theoretical" id="id7">[BAS15]</a> for details.</p>
<p>First dividing estimators into subgroups, take the average score as the
subgroup score. Finally, take the maximization of all subgroup outlier
scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – The score matrix outputted from various estimators</li>
<li><strong>n_buckets</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – The number of subgroups to build</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='static'</em><em>)</em>) – {‘static’, ‘dynamic’}, if ‘dynamic’, build subgroups
randomly with dynamic bucket size.</li>
<li><strong>bootstrap_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether estimators are drawn with replacement.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The combined outlier scores.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Numpy array of shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-pyod.models.hbos">
<span id="pyod-models-hbos-module"></span><h2>pyod.models.hbos module<a class="headerlink" href="#module-pyod.models.hbos" title="Permalink to this headline">¶</a></h2>
<p>Histogram-based Outlier Detection (HBOS)</p>
<dl class="class">
<dt id="pyod.models.hbos.HBOS">
<em class="property">class </em><code class="descclassname">pyod.models.hbos.</code><code class="descname">HBOS</code><span class="sig-paren">(</span><em>n_bins=10</em>, <em>alpha=0.1</em>, <em>tol=0.5</em>, <em>contamination=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.hbos.HBOS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Histogram- based outlier detection (HBOS) is an efficient unsupervised
method [1]. It assumes the feature independence and calculates the degree
of outlyingness by building histograms. See <a class="reference internal" href="#goldstein2012histogram" id="id8">[BGD12]</a>
for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_bins</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of bins</li>
<li><strong>alpha</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The regularizer for preventing overflow</li>
<li><strong>tol</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The parameter to decide the flexibility while dealing
the samples falling outside the bins.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>bin_edges_</strong> (<em>numpy array of shape</em><em> (</em><em>n_bins + 1</em><em>, </em><em>n_features</em><em> )</em>) – The edges of the bins</li>
<li><strong>hist_</strong> (<em>numpy array of shape</em><em> (</em><em>n_bins</em><em>, </em><em>n_features</em><em>)</em>) – The density of each histogram</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.hbos.HBOS.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.hbos.HBOS.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.hbos.HBOS.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id9">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.hbos.HBOS.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.hbos.HBOS.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.feature_bagging">
<span id="pyod-models-feature-bagging-module"></span><h2>pyod.models.feature_bagging module<a class="headerlink" href="#module-pyod.models.feature_bagging" title="Permalink to this headline">¶</a></h2>
<p>Feature bagging detector</p>
<dl class="class">
<dt id="pyod.models.feature_bagging.FeatureBagging">
<em class="property">class </em><code class="descclassname">pyod.models.feature_bagging.</code><code class="descname">FeatureBagging</code><span class="sig-paren">(</span><em>base_estimator=None</em>, <em>n_estimators=10</em>, <em>contamination=0.1</em>, <em>max_features=1.0</em>, <em>bootstrap_features=False</em>, <em>check_estimator=True</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>combination='average'</em>, <em>estimator_params={}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>A feature bagging detector is a meta estimator that fits a number of
base detectors on various sub-samples of the dataset and use averaging
or other combination methods to improve the predictive accuracy and
control over-fitting.</p>
<p>The sub-sample size is always the same as the original input sample size
but the features are randomly sampled from half of the features to all
features.</p>
<p>By default, LOF is used as the base estimator. However, any estimator
could be used as the base estimator, such as kNN and ABOD.</p>
<p>Feature bagging first construct n subsamples by random selecting a subset
of features, which induces the diversity of base estimators.</p>
<p>Finally, the prediction score is generated by averaging/taking the
maximum of all base detectors. See <a class="reference internal" href="#lazarevic2005feature" id="id10">[BLK05]</a> for
details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>base_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><em>object</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The base estimator to fit on random subsets of
the dataset. If None, then the base estimator is a LOF detector.</li>
<li><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of base estimators in the ensemble.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The number of features to draw from X to train
each base estimator.
- If int, then draw <cite>max_features</cite> features.
- If float, then draw <cite>max_features * X.shape[1]</cite> features.</li>
<li><strong>bootstrap_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether features are drawn with replacement.</li>
<li><strong>check_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If set to True, check whether the base estimator
is consistent with sklearn standard</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of jobs to run in parallel for both <cite>fit</cite> and
<cite>predict</cite>. If -1, then the number of jobs is set to the number of cores</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>combination</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='average'</em><em>)</em>) – the method of combination:
- if ‘average’: take the average of all detectors
- if ‘max’: take the maximum scores of all detectors</li>
<li><strong>estimator_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The list of attributes to use as parameters
when instantiating a new base estimator. If none are given,
default parameters are used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id11">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.feature_bagging.FeatureBagging.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.feature_bagging.FeatureBagging.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.iforest">
<span id="pyod-models-iforest-module"></span><h2>pyod.models.iforest module<a class="headerlink" href="#module-pyod.models.iforest" title="Permalink to this headline">¶</a></h2>
<p>IsolationForest Outlier Detector. Implemented on scikit-learn library.</p>
<dl class="class">
<dt id="pyod.models.iforest.IForest">
<em class="property">class </em><code class="descclassname">pyod.models.iforest.</code><code class="descname">IForest</code><span class="sig-paren">(</span><em>n_estimators=100</em>, <em>max_samples='auto'</em>, <em>contamination=0.1</em>, <em>max_features=1.0</em>, <em>bootstrap=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.iforest.IForest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn Isolation Forest with more functionalities.</p>
<p>The IsolationForest ‘isolates’ observations by randomly selecting a
feature and then randomly selecting a split value between the maximum and
minimum values of the selected feature.
See <a class="reference internal" href="#liu2008isolation" id="id12">[BLTZ08]</a><a class="reference internal" href="#liu2012isolation" id="id13">[BLTZ12]</a> for details.</p>
<p>Since recursive partitioning can be represented by a tree structure, the
number of splittings required to isolate a sample is equivalent to the path
length from the root node to the terminating node.</p>
<p>This path length, averaged over a forest of such random trees, is a
measure of normality and our decision function.</p>
<p>Random partitioning produces noticeably shorter paths for anomalies.
Hence, when a forest of random trees collectively produce shorter path
lengths for particular samples, they are highly likely to be anomalies.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – The number of base estimators in the ensemble.</li>
<li><strong>max_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – <p>The number of samples to draw from X to train
each base estimator.</p>
<blockquote>
<div><ul>
<li>If int, then draw <cite>max_samples</cite> samples.</li>
<li>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</li>
<li>If “auto”, then <cite>max_samples=min(256, n_samples)</cite>.</li>
</ul>
</div></blockquote>
</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – <p>The number of features to draw from X to
train each base estimator.</p>
<blockquote>
<div><ul>
<li>If int, then draw <cite>max_features</cite> features.</li>
<li>If float, then draw <cite>max_features * X.shape[1]</cite> features.</li>
</ul>
</div></blockquote>
</li>
<li><strong>bootstrap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, individual trees are fit on random subsets of
the training data sampled with replacement. If False, sampling without
replacement is performed.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of jobs to run in parallel for both <cite>fit</cite> and
<cite>predict</cite>. If -1, then the number of jobs is set to the number of cores</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Controls the verbosity of the tree building process.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.IForest.estimators_" title="pyod.models.IForest.estimators_"><strong>estimators_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – The collection of fitted sub-estimators.</li>
<li><a class="reference internal" href="#pyod.models.IForest.estimators_samples_" title="pyod.models.IForest.estimators_samples_"><strong>estimators_samples_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em> or </em><em>arrays</em>) – The subset of drawn samples (i.e., the
in-bag samples) for each base estimator.</li>
<li><a class="reference internal" href="#pyod.models.IForest.max_samples_" title="pyod.models.IForest.max_samples_"><strong>max_samples_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The actual number of samples.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.iforest.IForest.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.iforest.IForest.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.iforest.IForest.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id14">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.iforest.IForest.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.iforest.IForest.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.knn">
<span id="pyod-models-knn-module"></span><h2>pyod.models.knn module<a class="headerlink" href="#module-pyod.models.knn" title="Permalink to this headline">¶</a></h2>
<p>k-Nearest Neighbors Detector (kNN)</p>
<dl class="class">
<dt id="pyod.models.knn.KNN">
<em class="property">class </em><code class="descclassname">pyod.models.knn.</code><code class="descname">KNN</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>n_neighbors=5</em>, <em>method='largest'</em>, <em>radius=1.0</em>, <em>algorithm='auto'</em>, <em>leaf_size=30</em>, <em>metric='minkowski'</em>, <em>p=2</em>, <em>metric_params=None</em>, <em>n_jobs=1</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.knn.KNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>kNN class for outlier detection.
For an observation, its distance to its kth nearest neighbor could be
viewed as the outlying score. It could be viewed as a way to measure
the density. See <a class="reference internal" href="#ramaswamy2000efficient" id="id15">[BRRS00]</a><a class="reference internal" href="#angiulli2002fast" id="id16">[BAP02]</a> for
details.</p>
<p>Three kNN detectors are supported:
largest: use the distance to the kth neighbor as the outlier score
mean: use the average of all k neighbors as the outlier score
median: use the median of the distance to k neighbors as the outlier score</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – Number of neighbors to use by default
for k neighbors queries.</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='largest'</em><em>)</em>) – <p>{‘largest’, ‘mean’, ‘median’}</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier
score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the
outlier score</li>
</ul>
</li>
<li><strong>radius</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1.0</em><em>)</em>) – Range of parameter space to use by default for
radius_neighbors queries. Not applicable</li>
<li><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<blockquote>
<div><ul>
<li>’ball_tree’ will use BallTree</li>
<li>’kd_tree’ will use KDTree</li>
<li>’brute’ will use a brute-force search.</li>
<li>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#pyod.models.knn.KNN.fit" title="pyod.models.knn.KNN.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</li>
</ul>
</div></blockquote>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</li>
<li><strong>leaf_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=30</em><em>)</em>) – Leaf size passed to BallTree or KDTree. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</li>
<li><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric used for the distance computation. Any metric from
scikit-learn or scipy.spatial.distance can be used.</p>
<p>If ‘precomputed’, the training input X is expected to be a distance
matrix.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Valid values for metric are:</p>
<ul>
<li>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’,
‘l2’,’manhattan’]</li>
<li>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’,
‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’,
‘kulsinski’, ‘mahalanobis’, ‘matching’, ‘minkowski’,
‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’,
‘sokalsneath’, ‘sqeuclidean’, ‘yule’]</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=2</em><em>)</em>) – Parameter for the Minkowski metric for sklearn.metrics.pairwise.
pairwise_distances.
When p = 1, this is equivalent to using manhattan_distance (l1), and
euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance
(l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html</a></li>
<li><strong>metric_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Additional keyword arguments for the metric function.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.knn.KNN.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.knn.KNN.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.knn.KNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id17">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.knn.KNN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.knn.KNN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.lof">
<span id="pyod-models-lof-module"></span><h2>pyod.models.lof module<a class="headerlink" href="#module-pyod.models.lof" title="Permalink to this headline">¶</a></h2>
<p>Local Outlier Factor (LOF). Implemented on scikit-learn library.</p>
<dl class="class">
<dt id="pyod.models.lof.LOF">
<em class="property">class </em><code class="descclassname">pyod.models.lof.</code><code class="descname">LOF</code><span class="sig-paren">(</span><em>n_neighbors=20</em>, <em>algorithm='auto'</em>, <em>leaf_size=30</em>, <em>metric='minkowski'</em>, <em>p=2</em>, <em>metric_params=None</em>, <em>contamination=0.1</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.lof.LOF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn LOF Class with more functionalities.
Unsupervised Outlier Detection using Local Outlier Factor (LOF).</p>
<p>The anomaly score of each sample is called Local Outlier Factor.
It measures the local deviation of density of a given sample with
respect to its neighbors.
It is local in that the anomaly score depends on how isolated the object
is with respect to the surrounding neighborhood.
More precisely, locality is given by k-nearest neighbors, whose distance
is used to estimate the local density.
By comparing the local density of a sample to the local densities of
its neighbors, one can identify samples that have a substantially lower
density than their neighbors. These are considered outliers.
See <a class="reference internal" href="#breunig2000lof" id="id18">[BBKNS00]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Number of neighbors to use by default for
k neighbors.
If n_neighbors is larger than the number of samples provided,
all samples will be used.</li>
<li><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<blockquote>
<div><ul>
<li>’ball_tree’ will use BallTree</li>
<li>’kd_tree’ will use KDTree</li>
<li>’brute’ will use a brute-force search.</li>
<li>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#pyod.models.lof.LOF.fit" title="pyod.models.lof.LOF.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</li>
</ul>
</div></blockquote>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</li>
<li><strong>leaf_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=30</em><em>)</em>) – Leaf size passed to BallTree or KDTree. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</li>
<li><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric used for the distance computation. Any metric from
scikit-learn or scipy.spatial.distance can be used.</p>
<p>If ‘precomputed’, the training input X is expected to be a distance
matrix.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Valid values for metric are:</p>
<ul>
<li>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’,
‘l2’,’manhattan’]</li>
<li>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’,
‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’,
‘kulsinski’, ‘mahalanobis’, ‘matching’, ‘minkowski’,
‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’,
‘sokalsneath’, ‘sqeuclidean’, ‘yule’]</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=2</em><em>)</em>) – Parameter for the Minkowski metric for sklearn.metrics.pairwise.
pairwise_distances.
When p = 1, this is equivalent to using manhattan_distance (l1), and
euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance
(l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html</a></li>
<li><strong>metric_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Additional keyword arguments for the metric function.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.LOF.n_neighbors_" title="pyod.models.LOF.n_neighbors_"><strong>n_neighbors_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The actual number of neighbors used for
kneighbors queries.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.lof.LOF.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.lof.LOF.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.lof.LOF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id19">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.lof.LOF.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.lof.LOF.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.mcd">
<span id="pyod-models-mcd-module"></span><h2>pyod.models.mcd module<a class="headerlink" href="#module-pyod.models.mcd" title="Permalink to this headline">¶</a></h2>
<p>Outlier Detection with Minimum Covariance Determinant (MCD)</p>
<dl class="class">
<dt id="pyod.models.mcd.MCD">
<em class="property">class </em><code class="descclassname">pyod.models.mcd.</code><code class="descname">MCD</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>store_precision=True</em>, <em>assume_centered=False</em>, <em>support_fraction=None</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.mcd.MCD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>An object for detecting outliers in a Gaussian distributed dataset using
Minimum Covariance Determinant (MCD): robust estimator of covariance.</p>
<p>The Minimum Covariance Determinant covariance estimator is to be applied
on Gaussian-distributed data, but could still be relevant on data
drawn from a unimodal, symmetric distribution. It is not meant to be used
with multi-modal data (the algorithm used to fit a MinCovDet object is
likely to fail in such a case).
One should consider projection pursuit methods to deal with multi-modal
datasets.</p>
<p>First fit a minimum covariance determinant model and then compute the
Mahalanobis distance as the outlier degree of the data</p>
<p>See <a class="reference internal" href="#rousseeuw1999fast" id="id20">[BRD99]</a><a class="reference internal" href="#hardin2004outlier" id="id21">[BHR04]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>store_precision</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Specify if the estimated precision is stored.</li>
<li><strong>assume_centered</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, the support of the robust location and
the covariance estimates is computed, and a covariance estimate is
recomputed from it, without centering the data.
Useful to work with data whose mean is significantly equal to
zero but is not exactly zero.
If False, the robust location and covariance are directly computed
with the FastMCD algorithm without additional treatment.</li>
<li><strong>support_fraction</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The proportion of points to be included in the
support of the raw MCD estimate. Default is None, which implies that
the minimum value of support_fraction will be used within the
algorithm: [n_sample + n_features + 1] / 2</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.MCD.raw_location_" title="pyod.models.MCD.raw_location_"><strong>raw_location_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – The raw robust estimated location before correction
and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.raw_covariance_" title="pyod.models.MCD.raw_covariance_"><strong>raw_covariance_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – The raw robust estimated covariance before
correction and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.raw_support_" title="pyod.models.MCD.raw_support_"><strong>raw_support_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – A mask of the observations that have been used to
compute the raw robust estimates of location and shape, before
correction and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.location_" title="pyod.models.MCD.location_"><strong>location_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Estimated robust location</li>
<li><a class="reference internal" href="#pyod.models.MCD.covariance_" title="pyod.models.MCD.covariance_"><strong>covariance_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – Estimated robust covariance matrix</li>
<li><a class="reference internal" href="#pyod.models.MCD.precision_" title="pyod.models.MCD.precision_"><strong>precision_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – Estimated pseudo inverse matrix.
(stored only if store_precision is True)</li>
<li><a class="reference internal" href="#pyod.models.MCD.support_" title="pyod.models.MCD.support_"><strong>support_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – A mask of the observations that have been used to compute
the robust estimates of location and shape.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.mcd.MCD.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.mcd.MCD.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.mcd.MCD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id22">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.mcd.MCD.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.mcd.MCD.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.ocsvm">
<span id="pyod-models-ocsvm-module"></span><h2>pyod.models.ocsvm module<a class="headerlink" href="#module-pyod.models.ocsvm" title="Permalink to this headline">¶</a></h2>
<p>One-class SVM detector. Implemented on scikit-learn library.</p>
<dl class="class">
<dt id="pyod.models.ocsvm.OCSVM">
<em class="property">class </em><code class="descclassname">pyod.models.ocsvm.</code><code class="descname">OCSVM</code><span class="sig-paren">(</span><em>kernel='rbf'</em>, <em>degree=3</em>, <em>gamma='auto'</em>, <em>coef0=0.0</em>, <em>tol=0.001</em>, <em>nu=0.5</em>, <em>shrinking=True</em>, <em>cache_size=200</em>, <em>verbose=False</em>, <em>max_iter=-1</em>, <em>contamination=0.1</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ocsvm.OCSVM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn one-class SVM Class with more functionalities.
Unsupervised Outlier Detection.</p>
<p>Estimate the support of a high-dimensional distribution.</p>
<p>The implementation is based on libsvm.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection">http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection</a>
and <a class="reference internal" href="#ma2003time" id="id23">[BMP03]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='rbf'</em><em>)</em>) – Specifies the kernel type to be used in the algorithm.
It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or
a callable.
If none is given, ‘rbf’ will be used. If a callable is given it is
used to precompute the kernel matrix.</li>
<li><strong>degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=3</em><em>)</em>) – Degree of the polynomial kernel function (‘poly’).
Ignored by all other kernels.</li>
<li><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default='auto'</em><em>)</em>) – Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
If gamma is ‘auto’ then 1/n_features will be used instead.</li>
<li><strong>coef0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.0</em><em>)</em>) – Independent term in kernel function.
It is only significant in ‘poly’ and ‘sigmoid’.</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Tolerance for stopping criterion.</li>
<li><strong>nu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – An upper bound on the fraction of training
errors and a lower bound of the fraction of support
vectors. Should be in the interval (0, 1]. By default 0.5
will be taken.</li>
<li><strong>shrinking</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use the shrinking heuristic.</li>
<li><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Specify the size of the kernel cache (in MB).</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default: False</em>) – Enable verbose output. Note that this setting takes
advantage of a per-process runtime setting in libsvm that, if enabled,
may not work properly in a multithreaded context.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Hard limit on iterations within solver, or -1 for no
limit.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – The seed of the pseudo random number generator to use
when shuffling the data.
If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.MCD.support_" title="pyod.models.MCD.support_"><strong>support_</strong></a> (<em>array-like</em><em>, </em><em>shape =</em><em> [</em><em>n_SV</em><em>]</em>) – Indices of support vectors.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.support_vectors_" title="pyod.models.OCSVM.support_vectors_"><strong>support_vectors_</strong></a> (<em>array-like</em><em>, </em><em>shape =</em><em> [</em><em>nSV</em><em>, </em><em>n_features</em><em>]</em>) – Support vectors.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.dual_coef_" title="pyod.models.OCSVM.dual_coef_"><strong>dual_coef_</strong></a> (<em>array</em><em>, </em><em>shape =</em><em> [</em><em>1</em><em>, </em><em>n_SV</em><em>]</em>) – Coefficients of the support vectors in the
decision function.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.coef_" title="pyod.models.OCSVM.coef_"><strong>coef_</strong></a> (<em>array</em><em>, </em><em>shape =</em><em> [</em><em>1</em><em>, </em><em>n_features</em><em>]</em>) – <p>Weights assigned to the features (coefficients
in the primal problem). This is only available in the case of
a linear kernel.</p>
<p><cite>coef_</cite> is readonly property derived from <cite>dual_coef_</cite> and
<cite>support_vectors_</cite></p>
</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.intercept_" title="pyod.models.OCSVM.intercept_"><strong>intercept_</strong></a> – Constant in the decision function.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>sample_weight=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id24">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ocsvm.OCSVM.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ocsvm.OCSVM.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models.pca">
<span id="pyod-models-pca-module"></span><h2>pyod.models.pca module<a class="headerlink" href="#module-pyod.models.pca" title="Permalink to this headline">¶</a></h2>
<p>Principal Component Analysis (PCA) Outlier Detector</p>
<dl class="class">
<dt id="pyod.models.pca.PCA">
<em class="property">class </em><code class="descclassname">pyod.models.pca.</code><code class="descname">PCA</code><span class="sig-paren">(</span><em>n_components=None</em>, <em>n_selected_components=None</em>, <em>contamination=0.1</em>, <em>copy=True</em>, <em>whiten=False</em>, <em>svd_solver='auto'</em>, <em>tol=0.0</em>, <em>iterated_power='auto'</em>, <em>random_state=None</em>, <em>weighted=True</em>, <em>standardization=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.pca.PCA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Principal component analysis (PCA) can be used in detecting outliers. PCA
is a linear dimensionality reduction using Singular Value Decomposition
of the data to project it to a lower dimensional space.</p>
<p>In this procedure, covariance matrix of the data can be decomposed to
orthogonal vectors, called eigenvectors, associated with eigenvalues. The
eigenvectors with high eigenvalues capture most of the variance in the
data.</p>
<p>Therefore, a low dimensional hyperplane constructed by k eigenvectors can
capture most of the variance in the data. However, outliers are different
from normal data points, which is more obvious on the hyperplane
constructed by the eigenvectors with small eigenvalues.</p>
<p>Therefore, outlier scores can be obtained as the sum of the projected
distance of a sample on all eigenvectors.
See <a class="reference internal" href="#shyu2003novel" id="id25">[BSCSC03]</a><a class="reference internal" href="#aggarwal2015outlier" id="id26">[BAgg15]</a> for details.</p>
<p>Score(X) = Sum of weighted euclidean distance between each sample to the
hyperplane constructed by the selected eigenvectors</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_components</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>Number of principal components to keep.
if n_components is not set all components are kept:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">==</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
</pre></div>
</div>
<p>if n_components == ‘mle’ and svd_solver == ‘full’, Minka’s MLE is used
to guess the dimension
if <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">n_components</span> <span class="pre">&lt;</span> <span class="pre">1</span></code> and svd_solver == ‘full’, select the number
of components such that the amount of variance that needs to be
explained is greater than the percentage specified by n_components
n_components cannot be equal to n_features for svd_solver == ‘arpack’.</p>
</li>
<li><strong>n_selected_components</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Number of selected principal components
for calculating the outlier scores. It is not necessarily equal to
the total number of the principal components. If not set, use
all principal components.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>copy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em> (</em><em>default True</em><em>)</em>) – If False, data passed to fit are overwritten and running
fit(X).transform(X) will not yield the expected results,
use fit_transform(X) instead.</li>
<li><strong>whiten</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default False</em><em>)</em>) – <p>When True (False by default) the <cite>components_</cite> vectors are
multiplied by the square root of n_samples and then divided by the
singular values to ensure uncorrelated outputs with unit
component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometime
improve the predictive accuracy of the downstream estimators by
making their data respect some hard-wired assumptions.</p>
</li>
<li><strong>svd_solver</strong> (<em>str {'auto'</em><em>, </em><em>'full'</em><em>, </em><em>'arpack'</em><em>, </em><em>'randomized'}</em>) – <dl class="docutils">
<dt>auto :</dt>
<dd>the solver is selected by a default policy based on <cite>X.shape</cite> and
<cite>n_components</cite>: if the input data is larger than 500x500 and the
number of components to extract is lower than 80% of the smallest
dimension of the data, then the more efficient ‘randomized’
method is enabled. Otherwise the exact full SVD is computed and
optionally truncated afterwards.</dd>
<dt>full :</dt>
<dd>run exact full SVD calling the standard LAPACK solver via
<cite>scipy.linalg.svd</cite> and select the components by postprocessing</dd>
<dt>arpack :</dt>
<dd>run SVD truncated to n_components calling ARPACK solver via
<cite>scipy.sparse.linalg.svds</cite>. It requires strictly
0 &lt; n_components &lt; X.shape[1]</dd>
<dt>randomized :</dt>
<dd>run randomized SVD by the method of Halko et al.</dd>
</dl>
</li>
<li><strong>tol</strong> (<em>float &gt;= 0</em><em>, </em><em>optional</em><em> (</em><em>default .0</em><em>)</em>) – Tolerance for singular values computed by
svd_solver == ‘arpack’.</li>
<li><strong>iterated_power</strong> (<em>int &gt;= 0</em><em>, or </em><em>'auto'</em><em>, </em><em>(</em><em>default 'auto'</em><em>)</em>) – Number of iterations for the power method computed
by svd_solver == ‘randomized’.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal notranslate"><span class="pre">svd_solver</span></code> == ‘arpack’ or ‘randomized’.</li>
<li><strong>weighted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, the eigenvalues are used in score computation.
The eigenvectors with samll eigenvalues comes with more importance
in outlier score calculation.</li>
<li><strong>standardization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, perform standardization first to convert
data to zero mean and unit variance.
See <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html">http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html</a></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>components_</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>, </em><em>n_features</em><em>)</em>) – Components with maximum variance.</li>
<li><a class="reference internal" href="#pyod.models.PCA.explained_variance_ratio_" title="pyod.models.PCA.explained_variance_ratio_"><strong>explained_variance_ratio_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>,</em><em>)</em>) – Percentage of variance explained by each
of the selected components. If k is not set then all components are
stored and the sum of explained variances is equal to 1.0.</li>
<li><a class="reference internal" href="#pyod.models.PCA.singular_values_" title="pyod.models.PCA.singular_values_"><strong>singular_values_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>,</em><em>)</em>) – The singular values corresponding to each of the
selected components. The singular values are equal to the 2-norms of
the <code class="docutils literal notranslate"><span class="pre">n_components</span></code> variables in the lower-dimensional space.</li>
<li><a class="reference internal" href="#pyod.models.PCA.mean_" title="pyod.models.PCA.mean_"><strong>mean_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Per-feature empirical mean, estimated from the training set.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.pca.PCA.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.pca.PCA.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.pca.PCA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id27">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.pca.PCA.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.pca.PCA.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyod.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyod.models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pyod.models.ABOD">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">ABOD</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>n_neighbors=5</em>, <em>method='fast'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ABOD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>ABOD class for Angle-base Outlier Detection.
For an observation, the variance of its weighted cosine scores to all
neighbors could be viewed as the outlying score.
See <a class="reference internal" href="#kriegel2008angle" id="id28">[BKZ+08]</a> for details.</p>
<p>Two version of ABOD are supported:
Fast ABOD: use k nearest neighbors to approximate for complexity reduction
Original ABOD: consider all training points with high time complexity at
O(n^3).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Number of neighbors to use by default
for k neighbors queries.</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>{‘fast’, ‘default’}</p>
<ul>
<li>’fast’: fast ABOD. Only consider n_neighbors of training points</li>
<li>’default’: original ABOD with all training points, which could be
slow</li>
</ul>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.ABOD.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ABOD.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/abod.html#ABOD.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.ABOD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id29">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.ABOD.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.ABOD.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.CBLOF">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">CBLOF</code><span class="sig-paren">(</span><em>n_clusters=8</em>, <em>contamination=0.1</em>, <em>clustering_estimator=None</em>, <em>alpha=0.9</em>, <em>beta=5</em>, <em>use_weights=False</em>, <em>check_estimator=True</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.CBLOF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>The CBLOF operator calculates the outlier score based on cluster-based
local outlier factor.</p>
<p>CBLOF takes as an input the data set and the cluster model that was
generated by a clustering algorithm. It classifies the clusters into small
clusters and large clusters using the parameters alpha and beta.
The anomaly score is then calculated based on the size of the cluster the
point belongs to as well as the distance to the nearest large cluster.</p>
<p>Use weighting for outlier factor based on the sizes of the clusters as
proposed in the original publication. Since this might lead to unexpected
behavior (outliers close to small clusters are not found), it is disabled
by default.Outliers scores are solely computed based on their distance to
the closest large cluster center.</p>
<p>By default, MiniBatchKMeans is used for clustering algorithm instead of
Squeezer algorithm mentioned in the original paper for multiple reasons.</p>
<p>See <a class="reference internal" href="#he2003discovering" id="id30">[BHXD03]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_clusters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=8</em><em>)</em>) – The number of clusters to form as well as the number of
centroids to generate.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>clustering_estimator</strong> (<em>Estimator</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – <p>The base clustering algorithm for performing
data clustering. A valid clustering algorithm should be passed in.
The estimator should have standard sklearn APIs, fit() and predict().
The estimator should have attributes labels_ and cluster_centers_.
If cluster_centers_ is not in the attributes once the model is fit, it
is calculated as the mean of the samples in a cluster.</p>
<p>If not set, CBLOF uses MiniBatchKMeans for scalability. See
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html</a></p>
</li>
<li><strong>alpha</strong> (<em>float in</em><em> (</em><em>0.5</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – Coefficient for deciding small and large clusters. The ratio
of the number of samples in large clusters to the number of samples in
small clusters.</li>
<li><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>float in</em><em> (</em><em>1</em><em>,</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em><em></em>) – Coefficient for deciding small and large clusters. For a list
sorted clusters by size <cite>|C1|, |C2|, …, |Cn|, beta = |Ck|/|Ck-1|</cite></li>
<li><strong>use_weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If set to True, the size of clusters are used as
weights in outlier score calculation.</li>
<li><strong>check_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If set to True, check whether the base estimator
is consistent with sklearn standard</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>clustering_estimator_</strong> (<em>Estimator</em>) – Base estimator for clustering.</li>
<li><strong>cluster_labels_</strong> (<em>list of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Cluster assignment for the training samples</li>
<li><strong>cluster_sizes_</strong> (<em>list of shape</em><em> (</em><em>n_clusters</em><em>,</em><em>)</em>) – The size of each cluster once fitted with the
training data</li>
<li><strong>cluster_centers_</strong> (<em>numpy array of shape</em><em> (</em><em>n_clusters</em><em>, </em><em>n_features</em><em>)</em>) – The center of each cluster.</li>
<li><strong>small_cluster_labels_</strong> (<em>list of clusters numbers</em>) – The cluster assignments belonging to small
clusters</li>
<li><strong>large_cluster_labels_</strong> (<em>list of clusters numbers</em>) – The cluster assignments belonging to large
clusters</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.CBLOF.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.CBLOF.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/cblof.html#CBLOF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.CBLOF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id31">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.CBLOF.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.CBLOF.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pyod.models.aom">
<code class="descclassname">pyod.models.</code><code class="descname">aom</code><span class="sig-paren">(</span><em>scores</em>, <em>n_buckets=5</em>, <em>method='static'</em>, <em>bootstrap_estimators=False</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#aom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.aom" title="Permalink to this definition">¶</a></dt>
<dd><p>Average of Maximum - An ensemble method for combining multiple
estimators. See <a class="reference internal" href="#aggarwal2015theoretical" id="id32">[BAS15]</a> for details.</p>
<p>First dividing estimators into subgroups, take the maximum score as the
subgroup score. Finally, take the average of all subgroup outlier scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – The score matrix outputted from various estimators</li>
<li><strong>n_buckets</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – The number of subgroups to build</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='static'</em><em>)</em>) – {‘static’, ‘dynamic’}, if ‘dynamic’, build subgroups
randomly with dynamic bucket size.</li>
<li><strong>bootstrap_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether estimators are drawn with replacement.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The combined outlier scores.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Numpy array of shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.moa">
<code class="descclassname">pyod.models.</code><code class="descname">moa</code><span class="sig-paren">(</span><em>scores</em>, <em>n_buckets=5</em>, <em>method='static'</em>, <em>bootstrap_estimators=False</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#moa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.moa" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximization of Average - An ensemble method for combining multiple
estimators. See <a class="reference internal" href="#aggarwal2015theoretical" id="id33">[BAS15]</a> for details.</p>
<p>First dividing estimators into subgroups, take the average score as the
subgroup score. Finally, take the maximization of all subgroup outlier
scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – The score matrix outputted from various estimators</li>
<li><strong>n_buckets</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – The number of subgroups to build</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='static'</em><em>)</em>) – {‘static’, ‘dynamic’}, if ‘dynamic’, build subgroups
randomly with dynamic bucket size.</li>
<li><strong>bootstrap_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether estimators are drawn with replacement.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The combined outlier scores.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Numpy array of shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.average">
<code class="descclassname">pyod.models.</code><code class="descname">average</code><span class="sig-paren">(</span><em>scores</em>, <em>estimator_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#average"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.average" title="Permalink to this definition">¶</a></dt>
<dd><p>Combine the outlier scores from multiple estimators by averaging</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – score matrix from multiple estimators on the same samples</li>
<li><strong>estimator_weight</strong> (<em>list of shape</em><em> (</em><em>1</em><em>, </em><em>n_estimators</em><em>)</em>) – if specified, using weighted average</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the combined outlier scores</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy array of shape (n_samples, )</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pyod.models.maximization">
<code class="descclassname">pyod.models.</code><code class="descname">maximization</code><span class="sig-paren">(</span><em>scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/combination.html#maximization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.maximization" title="Permalink to this definition">¶</a></dt>
<dd><p>Combine the outlier scores from multiple estimators by taking the maximum</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>scores</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_estimators</em><em>)</em>) – score matrix from multiple estimators on the same samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">the combined outlier scores</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy array of shape (n_samples, )</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="pyod.models.FeatureBagging">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">FeatureBagging</code><span class="sig-paren">(</span><em>base_estimator=None</em>, <em>n_estimators=10</em>, <em>contamination=0.1</em>, <em>max_features=1.0</em>, <em>bootstrap_features=False</em>, <em>check_estimator=True</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>combination='average'</em>, <em>estimator_params={}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.FeatureBagging" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>A feature bagging detector is a meta estimator that fits a number of
base detectors on various sub-samples of the dataset and use averaging
or other combination methods to improve the predictive accuracy and
control over-fitting.</p>
<p>The sub-sample size is always the same as the original input sample size
but the features are randomly sampled from half of the features to all
features.</p>
<p>By default, LOF is used as the base estimator. However, any estimator
could be used as the base estimator, such as kNN and ABOD.</p>
<p>Feature bagging first construct n subsamples by random selecting a subset
of features, which induces the diversity of base estimators.</p>
<p>Finally, the prediction score is generated by averaging/taking the
maximum of all base detectors. See <a class="reference internal" href="#lazarevic2005feature" id="id34">[BLK05]</a> for
details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>base_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><em>object</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The base estimator to fit on random subsets of
the dataset. If None, then the base estimator is a LOF detector.</li>
<li><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of base estimators in the ensemble.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The number of features to draw from X to train
each base estimator.
- If int, then draw <cite>max_features</cite> features.
- If float, then draw <cite>max_features * X.shape[1]</cite> features.</li>
<li><strong>bootstrap_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether features are drawn with replacement.</li>
<li><strong>check_estimator</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If set to True, check whether the base estimator
is consistent with sklearn standard</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of jobs to run in parallel for both <cite>fit</cite> and
<cite>predict</cite>. If -1, then the number of jobs is set to the number of cores</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the
random number generator; If RandomState instance, random_state is
the random number generator; If None, the random number generator
is the RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>combination</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='average'</em><em>)</em>) – the method of combination:
- if ‘average’: take the average of all detectors
- if ‘max’: take the maximum scores of all detectors</li>
<li><strong>estimator_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The list of attributes to use as parameters
when instantiating a new base estimator. If none are given,
default parameters are used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.FeatureBagging.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.FeatureBagging.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/feature_bagging.html#FeatureBagging.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.FeatureBagging.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id35">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.FeatureBagging.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.FeatureBagging.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.HBOS">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">HBOS</code><span class="sig-paren">(</span><em>n_bins=10</em>, <em>alpha=0.1</em>, <em>tol=0.5</em>, <em>contamination=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.HBOS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Histogram- based outlier detection (HBOS) is an efficient unsupervised
method [1]. It assumes the feature independence and calculates the degree
of outlyingness by building histograms. See <a class="reference internal" href="#goldstein2012histogram" id="id36">[BGD12]</a>
for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_bins</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of bins</li>
<li><strong>alpha</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The regularizer for preventing overflow</li>
<li><strong>tol</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The parameter to decide the flexibility while dealing
the samples falling outside the bins.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>bin_edges_</strong> (<em>numpy array of shape</em><em> (</em><em>n_bins + 1</em><em>, </em><em>n_features</em><em> )</em>) – The edges of the bins</li>
<li><strong>hist_</strong> (<em>numpy array of shape</em><em> (</em><em>n_bins</em><em>, </em><em>n_features</em><em>)</em>) – The density of each histogram</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.HBOS.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.HBOS.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/hbos.html#HBOS.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.HBOS.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id37">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.HBOS.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.HBOS.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.IForest">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">IForest</code><span class="sig-paren">(</span><em>n_estimators=100</em>, <em>max_samples='auto'</em>, <em>contamination=0.1</em>, <em>max_features=1.0</em>, <em>bootstrap=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.IForest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn Isolation Forest with more functionalities.</p>
<p>The IsolationForest ‘isolates’ observations by randomly selecting a
feature and then randomly selecting a split value between the maximum and
minimum values of the selected feature.
See <a class="reference internal" href="#liu2008isolation" id="id38">[BLTZ08]</a><a class="reference internal" href="#liu2012isolation" id="id39">[BLTZ12]</a> for details.</p>
<p>Since recursive partitioning can be represented by a tree structure, the
number of splittings required to isolate a sample is equivalent to the path
length from the root node to the terminating node.</p>
<p>This path length, averaged over a forest of such random trees, is a
measure of normality and our decision function.</p>
<p>Random partitioning produces noticeably shorter paths for anomalies.
Hence, when a forest of random trees collectively produce shorter path
lengths for particular samples, they are highly likely to be anomalies.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – The number of base estimators in the ensemble.</li>
<li><strong>max_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – <p>The number of samples to draw from X to train
each base estimator.</p>
<blockquote>
<div><ul>
<li>If int, then draw <cite>max_samples</cite> samples.</li>
<li>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</li>
<li>If “auto”, then <cite>max_samples=min(256, n_samples)</cite>.</li>
</ul>
</div></blockquote>
</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – <p>The number of features to draw from X to
train each base estimator.</p>
<blockquote>
<div><ul>
<li>If int, then draw <cite>max_features</cite> features.</li>
<li>If float, then draw <cite>max_features * X.shape[1]</cite> features.</li>
</ul>
</div></blockquote>
</li>
<li><strong>bootstrap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, individual trees are fit on random subsets of
the training data sampled with replacement. If False, sampling without
replacement is performed.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of jobs to run in parallel for both <cite>fit</cite> and
<cite>predict</cite>. If -1, then the number of jobs is set to the number of cores</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Controls the verbosity of the tree building process.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.IForest.estimators_" title="pyod.models.IForest.estimators_"><strong>estimators_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – The collection of fitted sub-estimators.</li>
<li><a class="reference internal" href="#pyod.models.IForest.estimators_samples_" title="pyod.models.IForest.estimators_samples_"><strong>estimators_samples_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em> or </em><em>arrays</em>) – The subset of drawn samples (i.e., the
in-bag samples) for each base estimator.</li>
<li><a class="reference internal" href="#pyod.models.IForest.max_samples_" title="pyod.models.IForest.max_samples_"><strong>max_samples_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The actual number of samples.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.IForest.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.IForest.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.IForest.estimators_">
<code class="descname">estimators_</code><a class="headerlink" href="#pyod.models.IForest.estimators_" title="Permalink to this definition">¶</a></dt>
<dd><p>The collection of fitted sub-estimators.
Decorator for scikit-learn Isolation Forest attributes.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.IForest.estimators_samples_">
<code class="descname">estimators_samples_</code><a class="headerlink" href="#pyod.models.IForest.estimators_samples_" title="Permalink to this definition">¶</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for
each base estimator.
Decorator for scikit-learn Isolation Forest attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/iforest.html#IForest.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.IForest.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.IForest.max_samples_">
<code class="descname">max_samples_</code><a class="headerlink" href="#pyod.models.IForest.max_samples_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of samples.
Decorator for scikit-learn Isolation Forest attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id40">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.IForest.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.IForest.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.KNN">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">KNN</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>n_neighbors=5</em>, <em>method='largest'</em>, <em>radius=1.0</em>, <em>algorithm='auto'</em>, <em>leaf_size=30</em>, <em>metric='minkowski'</em>, <em>p=2</em>, <em>metric_params=None</em>, <em>n_jobs=1</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.KNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>kNN class for outlier detection.
For an observation, its distance to its kth nearest neighbor could be
viewed as the outlying score. It could be viewed as a way to measure
the density. See <a class="reference internal" href="#ramaswamy2000efficient" id="id41">[BRRS00]</a><a class="reference internal" href="#angiulli2002fast" id="id42">[BAP02]</a> for
details.</p>
<p>Three kNN detectors are supported:
largest: use the distance to the kth neighbor as the outlier score
mean: use the average of all k neighbors as the outlier score
median: use the median of the distance to k neighbors as the outlier score</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>0.5</em><em>]</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – Number of neighbors to use by default
for k neighbors queries.</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='largest'</em><em>)</em>) – <p>{‘largest’, ‘mean’, ‘median’}</p>
<ul>
<li>largest: use the distance to the kth neighbor as the outlier
score</li>
<li>mean: use the average of all k neighbors as the outlier score</li>
<li>median: use the median of the distance to k neighbors as the
outlier score</li>
</ul>
</li>
<li><strong>radius</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1.0</em><em>)</em>) – Range of parameter space to use by default for
radius_neighbors queries. Not applicable</li>
<li><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<blockquote>
<div><ul>
<li>’ball_tree’ will use BallTree</li>
<li>’kd_tree’ will use KDTree</li>
<li>’brute’ will use a brute-force search.</li>
<li>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#pyod.models.KNN.fit" title="pyod.models.KNN.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</li>
</ul>
</div></blockquote>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</li>
<li><strong>leaf_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=30</em><em>)</em>) – Leaf size passed to BallTree or KDTree. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</li>
<li><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric used for the distance computation. Any metric from
scikit-learn or scipy.spatial.distance can be used.</p>
<p>If ‘precomputed’, the training input X is expected to be a distance
matrix.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Valid values for metric are:</p>
<ul>
<li>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’,
‘l2’,’manhattan’]</li>
<li>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’,
‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’,
‘kulsinski’, ‘mahalanobis’, ‘matching’, ‘minkowski’,
‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’,
‘sokalsneath’, ‘sqeuclidean’, ‘yule’]</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=2</em><em>)</em>) – Parameter for the Minkowski metric for sklearn.metrics.pairwise.
pairwise_distances.
When p = 1, this is equivalent to using manhattan_distance (l1), and
euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance
(l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html</a></li>
<li><strong>metric_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Additional keyword arguments for the metric function.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.KNN.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.KNN.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/knn.html#KNN.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.KNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id43">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.KNN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.KNN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.LOF">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">LOF</code><span class="sig-paren">(</span><em>n_neighbors=20</em>, <em>algorithm='auto'</em>, <em>leaf_size=30</em>, <em>metric='minkowski'</em>, <em>p=2</em>, <em>metric_params=None</em>, <em>contamination=0.1</em>, <em>n_jobs=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.LOF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn LOF Class with more functionalities.
Unsupervised Outlier Detection using Local Outlier Factor (LOF).</p>
<p>The anomaly score of each sample is called Local Outlier Factor.
It measures the local deviation of density of a given sample with
respect to its neighbors.
It is local in that the anomaly score depends on how isolated the object
is with respect to the surrounding neighborhood.
More precisely, locality is given by k-nearest neighbors, whose distance
is used to estimate the local density.
By comparing the local density of a sample to the local densities of
its neighbors, one can identify samples that have a substantially lower
density than their neighbors. These are considered outliers.
See <a class="reference internal" href="#breunig2000lof" id="id44">[BBKNS00]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Number of neighbors to use by default for
k neighbors.
If n_neighbors is larger than the number of samples provided,
all samples will be used.</li>
<li><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<blockquote>
<div><ul>
<li>’ball_tree’ will use BallTree</li>
<li>’kd_tree’ will use KDTree</li>
<li>’brute’ will use a brute-force search.</li>
<li>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#pyod.models.LOF.fit" title="pyod.models.LOF.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</li>
</ul>
</div></blockquote>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</li>
<li><strong>leaf_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=30</em><em>)</em>) – Leaf size passed to BallTree or KDTree. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</li>
<li><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric used for the distance computation. Any metric from
scikit-learn or scipy.spatial.distance can be used.</p>
<p>If ‘precomputed’, the training input X is expected to be a distance
matrix.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Valid values for metric are:</p>
<ul>
<li>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’,
‘l2’,’manhattan’]</li>
<li>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’,
‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’,
‘kulsinski’, ‘mahalanobis’, ‘matching’, ‘minkowski’,
‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’,
‘sokalsneath’, ‘sqeuclidean’, ‘yule’]</li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=2</em><em>)</em>) – Parameter for the Minkowski metric for sklearn.metrics.pairwise.
pairwise_distances.
When p = 1, this is equivalent to using manhattan_distance (l1), and
euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance
(l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html</a></li>
<li><strong>metric_params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Additional keyword arguments for the metric function.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
<li><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.LOF.n_neighbors_" title="pyod.models.LOF.n_neighbors_"><strong>n_neighbors_</strong></a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The actual number of neighbors used for
kneighbors queries.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.LOF.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.LOF.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/lof.html#LOF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.LOF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.LOF.n_neighbors_">
<code class="descname">n_neighbors_</code><a class="headerlink" href="#pyod.models.LOF.n_neighbors_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of neighbors used for kneighbors queries.
Decorator for scikit-learn LOF attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id45">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.LOF.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.LOF.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.MCD">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">MCD</code><span class="sig-paren">(</span><em>contamination=0.1</em>, <em>store_precision=True</em>, <em>assume_centered=False</em>, <em>support_fraction=None</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.MCD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>An object for detecting outliers in a Gaussian distributed dataset using
Minimum Covariance Determinant (MCD): robust estimator of covariance.</p>
<p>The Minimum Covariance Determinant covariance estimator is to be applied
on Gaussian-distributed data, but could still be relevant on data
drawn from a unimodal, symmetric distribution. It is not meant to be used
with multi-modal data (the algorithm used to fit a MinCovDet object is
likely to fail in such a case).
One should consider projection pursuit methods to deal with multi-modal
datasets.</p>
<p>First fit a minimum covariance determinant model and then compute the
Mahalanobis distance as the outlier degree of the data</p>
<p>See <a class="reference internal" href="#rousseeuw1999fast" id="id46">[BRD99]</a><a class="reference internal" href="#hardin2004outlier" id="id47">[BHR04]</a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>store_precision</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Specify if the estimated precision is stored.</li>
<li><strong>assume_centered</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, the support of the robust location and
the covariance estimates is computed, and a covariance estimate is
recomputed from it, without centering the data.
Useful to work with data whose mean is significantly equal to
zero but is not exactly zero.
If False, the robust location and covariance are directly computed
with the FastMCD algorithm without additional treatment.</li>
<li><strong>support_fraction</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The proportion of points to be included in the
support of the raw MCD estimate. Default is None, which implies that
the minimum value of support_fraction will be used within the
algorithm: [n_sample + n_features + 1] / 2</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.MCD.raw_location_" title="pyod.models.MCD.raw_location_"><strong>raw_location_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – The raw robust estimated location before correction
and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.raw_covariance_" title="pyod.models.MCD.raw_covariance_"><strong>raw_covariance_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – The raw robust estimated covariance before
correction and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.raw_support_" title="pyod.models.MCD.raw_support_"><strong>raw_support_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – A mask of the observations that have been used to
compute the raw robust estimates of location and shape, before
correction and re-weighting.</li>
<li><a class="reference internal" href="#pyod.models.MCD.location_" title="pyod.models.MCD.location_"><strong>location_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Estimated robust location</li>
<li><a class="reference internal" href="#pyod.models.MCD.covariance_" title="pyod.models.MCD.covariance_"><strong>covariance_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – Estimated robust covariance matrix</li>
<li><a class="reference internal" href="#pyod.models.MCD.precision_" title="pyod.models.MCD.precision_"><strong>precision_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>, </em><em>n_features</em><em>)</em>) – Estimated pseudo inverse matrix.
(stored only if store_precision is True)</li>
<li><a class="reference internal" href="#pyod.models.MCD.support_" title="pyod.models.MCD.support_"><strong>support_</strong></a> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – A mask of the observations that have been used to compute
the robust estimates of location and shape.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="pyod.models.MCD.covariance_">
<code class="descname">covariance_</code><a class="headerlink" href="#pyod.models.MCD.covariance_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimated robust covariance matrix.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.MCD.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/mcd.html#MCD.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.MCD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model using X as training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix</em><em>, </em><em>BallTree</em><em>, </em><em>KDTree}</em>) – Training data. If array or matrix,
shape [n_samples, n_features],
or [n_samples, n_samples] if metric=’precomputed’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.location_">
<code class="descname">location_</code><a class="headerlink" href="#pyod.models.MCD.location_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimated robust location.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.precision_">
<code class="descname">precision_</code><a class="headerlink" href="#pyod.models.MCD.precision_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimated pseudo inverse matrix.
(stored only if store_precision is True)</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id48">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.raw_covariance_">
<code class="descname">raw_covariance_</code><a class="headerlink" href="#pyod.models.MCD.raw_covariance_" title="Permalink to this definition">¶</a></dt>
<dd><p>The raw robust estimated location before correction and
re-weighting.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.raw_location_">
<code class="descname">raw_location_</code><a class="headerlink" href="#pyod.models.MCD.raw_location_" title="Permalink to this definition">¶</a></dt>
<dd><p>The raw robust estimated location before correction and
re-weighting.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.raw_support_">
<code class="descname">raw_support_</code><a class="headerlink" href="#pyod.models.MCD.raw_support_" title="Permalink to this definition">¶</a></dt>
<dd><p>A mask of the observations that have been used to compute
the raw robust estimates of location and shape, before correction
and re-weighting.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.MCD.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.MCD.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.MCD.support_">
<code class="descname">support_</code><a class="headerlink" href="#pyod.models.MCD.support_" title="Permalink to this definition">¶</a></dt>
<dd><p>A mask of the observations that have been used to compute
the robust estimates of location and shape.</p>
<p>Decorator for scikit-learn MinCovDet attributes.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.OCSVM">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">OCSVM</code><span class="sig-paren">(</span><em>kernel='rbf'</em>, <em>degree=3</em>, <em>gamma='auto'</em>, <em>coef0=0.0</em>, <em>tol=0.001</em>, <em>nu=0.5</em>, <em>shrinking=True</em>, <em>cache_size=200</em>, <em>verbose=False</em>, <em>max_iter=-1</em>, <em>contamination=0.1</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.OCSVM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Wrapper of scikit-learn one-class SVM Class with more functionalities.
Unsupervised Outlier Detection.</p>
<p>Estimate the support of a high-dimensional distribution.</p>
<p>The implementation is based on libsvm.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection">http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection</a>
and <a class="reference internal" href="#ma2003time" id="id49">[BMP03]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='rbf'</em><em>)</em>) – Specifies the kernel type to be used in the algorithm.
It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or
a callable.
If none is given, ‘rbf’ will be used. If a callable is given it is
used to precompute the kernel matrix.</li>
<li><strong>degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=3</em><em>)</em>) – Degree of the polynomial kernel function (‘poly’).
Ignored by all other kernels.</li>
<li><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default='auto'</em><em>)</em>) – Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
If gamma is ‘auto’ then 1/n_features will be used instead.</li>
<li><strong>coef0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.0</em><em>)</em>) – Independent term in kernel function.
It is only significant in ‘poly’ and ‘sigmoid’.</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Tolerance for stopping criterion.</li>
<li><strong>nu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – An upper bound on the fraction of training
errors and a lower bound of the fraction of support
vectors. Should be in the interval (0, 1]. By default 0.5
will be taken.</li>
<li><strong>shrinking</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to use the shrinking heuristic.</li>
<li><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Specify the size of the kernel cache (in MB).</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default: False</em>) – Enable verbose output. Note that this setting takes
advantage of a per-process runtime setting in libsvm that, if enabled,
may not work properly in a multithreaded context.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Hard limit on iterations within solver, or -1 for no
limit.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>
(</em><em>default=None</em><em>)</em>) – The seed of the pseudo random number generator to use
when shuffling the data.
If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <cite>np.random</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference internal" href="#pyod.models.MCD.support_" title="pyod.models.MCD.support_"><strong>support_</strong></a> (<em>array-like</em><em>, </em><em>shape =</em><em> [</em><em>n_SV</em><em>]</em>) – Indices of support vectors.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.support_vectors_" title="pyod.models.OCSVM.support_vectors_"><strong>support_vectors_</strong></a> (<em>array-like</em><em>, </em><em>shape =</em><em> [</em><em>nSV</em><em>, </em><em>n_features</em><em>]</em>) – Support vectors.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.dual_coef_" title="pyod.models.OCSVM.dual_coef_"><strong>dual_coef_</strong></a> (<em>array</em><em>, </em><em>shape =</em><em> [</em><em>1</em><em>, </em><em>n_SV</em><em>]</em>) – Coefficients of the support vectors in the
decision function.</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.coef_" title="pyod.models.OCSVM.coef_"><strong>coef_</strong></a> (<em>array</em><em>, </em><em>shape =</em><em> [</em><em>1</em><em>, </em><em>n_features</em><em>]</em>) – <p>Weights assigned to the features (coefficients
in the primal problem). This is only available in the case of
a linear kernel.</p>
<p><cite>coef_</cite> is readonly property derived from <cite>dual_coef_</cite> and
<cite>support_vectors_</cite></p>
</li>
<li><a class="reference internal" href="#pyod.models.OCSVM.intercept_" title="pyod.models.OCSVM.intercept_"><strong>intercept_</strong></a> – Constant in the decision function.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="pyod.models.OCSVM.coef_">
<code class="descname">coef_</code><a class="headerlink" href="#pyod.models.OCSVM.coef_" title="Permalink to this definition">¶</a></dt>
<dd><p>Weights assigned to the features (coefficients in the primal
problem). This is only available in the case of a linear kernel.
<cite>coef_</cite> is readonly property derived from <cite>dual_coef_</cite> and
<cite>support_vectors_</cite>
Decorator for scikit-learn One class SVM attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.OCSVM.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.OCSVM.dual_coef_">
<code class="descname">dual_coef_</code><a class="headerlink" href="#pyod.models.OCSVM.dual_coef_" title="Permalink to this definition">¶</a></dt>
<dd><p>Coefficients of the support vectors in the decision function.
Decorator for scikit-learn One class SVM attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>sample_weight=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/ocsvm.html#OCSVM.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.OCSVM.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.OCSVM.intercept_">
<code class="descname">intercept_</code><a class="headerlink" href="#pyod.models.OCSVM.intercept_" title="Permalink to this definition">¶</a></dt>
<dd><p>Constant in the decision function.
Decorator for scikit-learn One class SVM attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id50">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.OCSVM.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.OCSVM.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.OCSVM.support_">
<code class="descname">support_</code><a class="headerlink" href="#pyod.models.OCSVM.support_" title="Permalink to this definition">¶</a></dt>
<dd><p>Indices of support vectors.
Decorator for scikit-learn One class SVM attributes.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.OCSVM.support_vectors_">
<code class="descname">support_vectors_</code><a class="headerlink" href="#pyod.models.OCSVM.support_vectors_" title="Permalink to this definition">¶</a></dt>
<dd><p>Support vectors.
Decorator for scikit-learn One class SVM attributes.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pyod.models.PCA">
<em class="property">class </em><code class="descclassname">pyod.models.</code><code class="descname">PCA</code><span class="sig-paren">(</span><em>n_components=None</em>, <em>n_selected_components=None</em>, <em>contamination=0.1</em>, <em>copy=True</em>, <em>whiten=False</em>, <em>svd_solver='auto'</em>, <em>tol=0.0</em>, <em>iterated_power='auto'</em>, <em>random_state=None</em>, <em>weighted=True</em>, <em>standardization=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.PCA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pyod.models.base.BaseDetector" title="pyod.models.base.BaseDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyod.models.base.BaseDetector</span></code></a></p>
<p>Principal component analysis (PCA) can be used in detecting outliers. PCA
is a linear dimensionality reduction using Singular Value Decomposition
of the data to project it to a lower dimensional space.</p>
<p>In this procedure, covariance matrix of the data can be decomposed to
orthogonal vectors, called eigenvectors, associated with eigenvalues. The
eigenvectors with high eigenvalues capture most of the variance in the
data.</p>
<p>Therefore, a low dimensional hyperplane constructed by k eigenvectors can
capture most of the variance in the data. However, outliers are different
from normal data points, which is more obvious on the hyperplane
constructed by the eigenvectors with small eigenvalues.</p>
<p>Therefore, outlier scores can be obtained as the sum of the projected
distance of a sample on all eigenvectors.
See <a class="reference internal" href="#shyu2003novel" id="id51">[BSCSC03]</a><a class="reference internal" href="#aggarwal2015outlier" id="id52">[BAgg15]</a> for details.</p>
<p>Score(X) = Sum of weighted euclidean distance between each sample to the
hyperplane constructed by the selected eigenvectors</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_components</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>Number of principal components to keep.
if n_components is not set all components are kept:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">==</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
</pre></div>
</div>
<p>if n_components == ‘mle’ and svd_solver == ‘full’, Minka’s MLE is used
to guess the dimension
if <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">n_components</span> <span class="pre">&lt;</span> <span class="pre">1</span></code> and svd_solver == ‘full’, select the number
of components such that the amount of variance that needs to be
explained is greater than the percentage specified by n_components
n_components cannot be equal to n_features for svd_solver == ‘arpack’.</p>
</li>
<li><strong>n_selected_components</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Number of selected principal components
for calculating the outlier scores. It is not necessarily equal to
the total number of the principal components. If not set, use
all principal components.</li>
<li><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</li>
<li><strong>copy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em> (</em><em>default True</em><em>)</em>) – If False, data passed to fit are overwritten and running
fit(X).transform(X) will not yield the expected results,
use fit_transform(X) instead.</li>
<li><strong>whiten</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default False</em><em>)</em>) – <p>When True (False by default) the <cite>components_</cite> vectors are
multiplied by the square root of n_samples and then divided by the
singular values to ensure uncorrelated outputs with unit
component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometime
improve the predictive accuracy of the downstream estimators by
making their data respect some hard-wired assumptions.</p>
</li>
<li><strong>svd_solver</strong> (<em>str {'auto'</em><em>, </em><em>'full'</em><em>, </em><em>'arpack'</em><em>, </em><em>'randomized'}</em>) – <dl class="docutils">
<dt>auto :</dt>
<dd>the solver is selected by a default policy based on <cite>X.shape</cite> and
<cite>n_components</cite>: if the input data is larger than 500x500 and the
number of components to extract is lower than 80% of the smallest
dimension of the data, then the more efficient ‘randomized’
method is enabled. Otherwise the exact full SVD is computed and
optionally truncated afterwards.</dd>
<dt>full :</dt>
<dd>run exact full SVD calling the standard LAPACK solver via
<cite>scipy.linalg.svd</cite> and select the components by postprocessing</dd>
<dt>arpack :</dt>
<dd>run SVD truncated to n_components calling ARPACK solver via
<cite>scipy.sparse.linalg.svds</cite>. It requires strictly
0 &lt; n_components &lt; X.shape[1]</dd>
<dt>randomized :</dt>
<dd>run randomized SVD by the method of Halko et al.</dd>
</dl>
</li>
<li><strong>tol</strong> (<em>float &gt;= 0</em><em>, </em><em>optional</em><em> (</em><em>default .0</em><em>)</em>) – Tolerance for singular values computed by
svd_solver == ‘arpack’.</li>
<li><strong>iterated_power</strong> (<em>int &gt;= 0</em><em>, or </em><em>'auto'</em><em>, </em><em>(</em><em>default 'auto'</em><em>)</em>) – Number of iterations for the power method computed
by svd_solver == ‘randomized’.</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>,
</em><em>optional</em><em> (</em><em>default None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal notranslate"><span class="pre">svd_solver</span></code> == ‘arpack’ or ‘randomized’.</li>
<li><strong>weighted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, the eigenvalues are used in score computation.
The eigenvectors with samll eigenvalues comes with more importance
in outlier score calculation.</li>
<li><strong>standardization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, perform standardization first to convert
data to zero mean and unit variance.
See <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html">http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html</a></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>components_</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>, </em><em>n_features</em><em>)</em>) – Components with maximum variance.</li>
<li><a class="reference internal" href="#pyod.models.PCA.explained_variance_ratio_" title="pyod.models.PCA.explained_variance_ratio_"><strong>explained_variance_ratio_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>,</em><em>)</em>) – Percentage of variance explained by each
of the selected components. If k is not set then all components are
stored and the sum of explained variances is equal to 1.0.</li>
<li><a class="reference internal" href="#pyod.models.PCA.singular_values_" title="pyod.models.PCA.singular_values_"><strong>singular_values_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_components</em><em>,</em><em>)</em>) – The singular values corresponding to each of the
selected components. The singular values are equal to the 2-norms of
the <code class="docutils literal notranslate"><span class="pre">n_components</span></code> variables in the lower-dimensional space.</li>
<li><a class="reference internal" href="#pyod.models.PCA.mean_" title="pyod.models.PCA.mean_"><strong>mean_</strong></a> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Per-feature empirical mean, estimated from the training set.</li>
<li><strong>decision_scores_</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</li>
<li><strong>threshold_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</li>
<li><strong>labels_</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>either 0</em><em> or </em><em>1</em>) – The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pyod.models.PCA.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA.decision_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.PCA.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict anomaly score of X of the base classifiers.</p>
<p>The anomaly score of an input sample is computed based on different
detector algorithms. For consistency, outliers are assigned with
larger anomaly scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The anomaly score of the input samples.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.PCA.explained_variance_ratio_">
<code class="descname">explained_variance_ratio_</code><a class="headerlink" href="#pyod.models.PCA.explained_variance_ratio_" title="Permalink to this definition">¶</a></dt>
<dd><p>Percentage of variance explained by each of the selected components.
If k is not set then all components are stored and the sum of explained
variances is equal to 1.0.
Decorator for scikit-learn PCA attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyod/models/pca.html#PCA.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyod.models.PCA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only
if they are supported by the base estimator.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">return self</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit detector and predict if a particular sample is an outlier or
not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the
fitted model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.fit_predict_score">
<code class="descname">fit_predict_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>scoring='roc_auc_score'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.fit_predict_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the detector, predict on samples, and evaluate the model by
ROC and Precision &#64; rank n</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>y</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Outlier labels of the input samples</li>
<li><strong>scoring</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='roc_auc_score'</em><em>)</em>) – <p>Evaluation metric</p>
<p>-‘ roc_auc_score’: ROC score
- ‘prc_n_score’: Precision &#64; rank n score</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Evaluation score</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mapping of string to any
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)">str</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.PCA.mean_">
<code class="descname">mean_</code><a class="headerlink" href="#pyod.models.PCA.mean_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per-feature empirical mean, estimated from the training set.
Decorator for scikit-learn PCA attributes.</p>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict if a particular sample is an outlier or not.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">For each observation, tells whether or not
it should be considered as an outlier according to the fitted
model. 0 stands for inliers and 1 for outliers.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array, shape (n_samples,)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>method='linear'</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the probability of a sample being outlier. Two approaches
are possible:</p>
<ol class="arabic simple">
<li>simply use Min-max conversion to linearly transform the outlier
scores into the range of [0,1]. The model must be
fitted first.</li>
<li>use unifying scores, see <a class="reference internal" href="#kriegel2011interpreting" id="id53">[BKKSZ11]</a>.</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The input samples</li>
<li><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='linear'</em><em>)</em>) – probability conversion method. It must be one of
‘linear’ or ‘unify’.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">For each observation, return the outlier probability, ranging
in [0,1]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array, shape (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyod.models.PCA.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#pyod.models.PCA.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html">http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html</a>
and sklearn/base.py for more information.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyod.models.PCA.singular_values_">
<code class="descname">singular_values_</code><a class="headerlink" href="#pyod.models.PCA.singular_values_" title="Permalink to this definition">¶</a></dt>
<dd><p>The singular values corresponding to each of the selected
components. The singular values are equal to the 2-norms of the
<code class="docutils literal notranslate"><span class="pre">n_components</span></code> variables in the lower-dimensional space.
Decorator for scikit-learn PCA attributes.</p>
</dd></dl>

</dd></dl>

<p class="rubric">References</p>
<p id="bibtex-bibliography-pyod.models-0"><table class="docutils citation" frame="void" id="aggarwal2015outlier" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BAgg15]</td><td><em>(<a class="fn-backref" href="#id26">1</a>, <a class="fn-backref" href="#id52">2</a>)</em> Charu&nbsp;C Aggarwal. Outlier analysis. In <em>Data mining</em>, 75–79. Springer, 2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="aggarwal2015theoretical" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BAS15]</td><td><em>(<a class="fn-backref" href="#id6">1</a>, <a class="fn-backref" href="#id7">2</a>, <a class="fn-backref" href="#id32">3</a>, <a class="fn-backref" href="#id33">4</a>)</em> Charu&nbsp;C Aggarwal and Saket Sathe. Theoretical foundations and algorithms for outlier ensembles. <em>ACM SIGKDD Explorations Newsletter</em>, 17(1):24–47, 2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="angiulli2002fast" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BAP02]</td><td><em>(<a class="fn-backref" href="#id16">1</a>, <a class="fn-backref" href="#id42">2</a>)</em> Fabrizio Angiulli and Clara Pizzuti. Fast outlier detection in high dimensional spaces. In <em>European Conference on Principles of Data Mining and Knowledge Discovery</em>, 15–27. Springer, 2002.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="breunig2000lof" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BBKNS00]</td><td><em>(<a class="fn-backref" href="#id18">1</a>, <a class="fn-backref" href="#id44">2</a>)</em> Markus&nbsp;M Breunig, Hans-Peter Kriegel, Raymond&nbsp;T Ng, and Jörg Sander. Lof: identifying density-based local outliers. In <em>ACM sigmod record</em>, volume&nbsp;29, 93–104. ACM, 2000.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="goldstein2012histogram" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BGD12]</td><td><em>(<a class="fn-backref" href="#id8">1</a>, <a class="fn-backref" href="#id36">2</a>)</em> Markus Goldstein and Andreas Dengel. Histogram-based outlier score (hbos): a fast unsupervised anomaly detection algorithm. <em>KI-2012: Poster and Demo Track</em>, pages 59–63, 2012.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hardin2004outlier" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BHR04]</td><td><em>(<a class="fn-backref" href="#id21">1</a>, <a class="fn-backref" href="#id47">2</a>)</em> Johanna Hardin and David&nbsp;M Rocke. Outlier detection in the multiple cluster setting using the minimum covariance determinant estimator. <em>Computational Statistics &amp; Data Analysis</em>, 44(4):625–638, 2004.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="he2003discovering" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BHXD03]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id30">2</a>)</em> Zengyou He, Xiaofei Xu, and Shengchun Deng. Discovering cluster-based local outliers. <em>Pattern Recognition Letters</em>, 24(9-10):1641–1650, 2003.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kriegel2011interpreting" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BKKSZ11]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>, <a class="fn-backref" href="#id5">3</a>, <a class="fn-backref" href="#id9">4</a>, <a class="fn-backref" href="#id11">5</a>, <a class="fn-backref" href="#id14">6</a>, <a class="fn-backref" href="#id17">7</a>, <a class="fn-backref" href="#id19">8</a>, <a class="fn-backref" href="#id22">9</a>, <a class="fn-backref" href="#id24">10</a>, <a class="fn-backref" href="#id27">11</a>, <a class="fn-backref" href="#id29">12</a>, <a class="fn-backref" href="#id31">13</a>, <a class="fn-backref" href="#id35">14</a>, <a class="fn-backref" href="#id37">15</a>, <a class="fn-backref" href="#id40">16</a>, <a class="fn-backref" href="#id43">17</a>, <a class="fn-backref" href="#id45">18</a>, <a class="fn-backref" href="#id48">19</a>, <a class="fn-backref" href="#id50">20</a>, <a class="fn-backref" href="#id53">21</a>)</em> Hans-Peter Kriegel, Peer Kroger, Erich Schubert, and Arthur Zimek. Interpreting and unifying outlier scores. In <em>Proceedings of the 2011 SIAM International Conference on Data Mining</em>, 13–24. SIAM, 2011.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kriegel2008angle" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BKZ+08]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id28">2</a>)</em> Hans-Peter Kriegel, Arthur Zimek, and others. Angle-based outlier detection in high-dimensional data. In <em>Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 444–452. ACM, 2008.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lazarevic2005feature" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BLK05]</td><td><em>(<a class="fn-backref" href="#id10">1</a>, <a class="fn-backref" href="#id34">2</a>)</em> Aleksandar Lazarevic and Vipin Kumar. Feature bagging for outlier detection. In <em>Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining</em>, 157–166. ACM, 2005.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="liu2008isolation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BLTZ08]</td><td><em>(<a class="fn-backref" href="#id12">1</a>, <a class="fn-backref" href="#id38">2</a>)</em> Fei&nbsp;Tony Liu, Kai&nbsp;Ming Ting, and Zhi-Hua Zhou. Isolation forest. In <em>Data Mining, 2008. ICDM‘08. Eighth IEEE International Conference on</em>, 413–422. IEEE, 2008.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="liu2012isolation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BLTZ12]</td><td><em>(<a class="fn-backref" href="#id13">1</a>, <a class="fn-backref" href="#id39">2</a>)</em> Fei&nbsp;Tony Liu, Kai&nbsp;Ming Ting, and Zhi-Hua Zhou. Isolation-based anomaly detection. <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>, 6(1):3, 2012.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ma2003time" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BMP03]</td><td><em>(<a class="fn-backref" href="#id23">1</a>, <a class="fn-backref" href="#id49">2</a>)</em> Junshui Ma and Simon Perkins. Time-series novelty detection using one-class support vector machines. In <em>Neural Networks, 2003. Proceedings of the International Joint Conference on</em>, volume&nbsp;3, 1741–1745. IEEE, 2003.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ramaswamy2000efficient" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BRRS00]</td><td><em>(<a class="fn-backref" href="#id15">1</a>, <a class="fn-backref" href="#id41">2</a>)</em> Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim. Efficient algorithms for mining outliers from large data sets. In <em>ACM Sigmod Record</em>, volume&nbsp;29, 427–438. ACM, 2000.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rousseeuw1999fast" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BRD99]</td><td><em>(<a class="fn-backref" href="#id20">1</a>, <a class="fn-backref" href="#id46">2</a>)</em> Peter&nbsp;J Rousseeuw and Katrien&nbsp;Van Driessen. A fast algorithm for the minimum covariance determinant estimator. <em>Technometrics</em>, 41(3):212–223, 1999.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="shyu2003novel" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[BSCSC03]</td><td><em>(<a class="fn-backref" href="#id25">1</a>, <a class="fn-backref" href="#id51">2</a>)</em> Mei-Ling Shyu, Shu-Ching Chen, Kanoksri Sarinnapakorn, and LiWu Chang. A novel anomaly detection scheme based on principal component classifier. Technical Report, MIAMI UNIV CORAL GABLES FL DEPT OF ELECTRICAL AND COMPUTER ENGINEERING, 2003.</td></tr>
</tbody>
</table>
</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h3><a href="index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="example.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_cc.html">API CheatSheet</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="pyod.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="pyod.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyod.html#module-pyod">Module contents</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="pyod.html"
                        title="previous chapter">API Reference</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pyod.utils.html"
                        title="next chapter">pyod.utils package</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/pyod.models.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pyod.utils.html" title="pyod.utils package"
             >next</a> |</li>
        <li class="right" >
          <a href="pyod.html" title="API Reference"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pyod 0.5.6 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pyod.html" >API Reference</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Yue Zhao.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.8.
    </div>
  </body>
</html>