

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Python API &mdash; LightGBM  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Parallel Learning Guide" href="Parallel-Learning-Guide.html" />
    <link rel="prev" title="Parameters Tuning" href="Parameters-Tuning.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> LightGBM
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Installation-Guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quick-Start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="Python-Intro.html">Python Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="Features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="Experiments.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameters.html">Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameters-Tuning.html">Parameters Tuning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-structure-api">Data Structure API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-api">Training API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scikit-learn-api">Scikit-learn API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#callbacks">Callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plotting">Plotting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Parallel-Learning-Guide.html">Parallel Learning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="GPU-Tutorial.html">GPU Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="Advanced-Topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="Development-Guide.html">Development Guide</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">LightGBM</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Python API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Python-API.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="python-api">
<h1>Python API<a class="headerlink" href="#python-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="data-structure-api">
<h2>Data Structure API<a class="headerlink" href="#data-structure-api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lightgbm.Dataset">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">Dataset</code><span class="sig-paren">(</span><em>data</em>, <em>label=None</em>, <em>reference=None</em>, <em>weight=None</em>, <em>group=None</em>, <em>init_score=None</em>, <em>silent=False</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>params=None</em>, <em>free_raw_data=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Dataset in LightGBM.</p>
<p>Constract Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>string</em><em>, </em><em>numpy array</em><em>, </em><em>scipy.sparse</em><em> or </em><em>list of numpy arrays</em>) – Data source of Dataset.
If string, it represents the path to txt file.</li>
<li><strong>label</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Label of the data.</li>
<li><strong>reference</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If this is Dataset for validation, training data should be used as reference.</li>
<li><strong>weight</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weight for each instance.</li>
<li><strong>group</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group/query size for Dataset.</li>
<li><strong>init_score</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score for Dataset.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to print messages during construction.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>params</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Other parameters.</li>
<li><strong>free_raw_data</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, raw data is freed after constructing inner Dataset.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lightgbm.Dataset.construct">
<code class="descname">construct</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Lazy init.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Constructed Dataset object.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.create_valid">
<code class="descname">create_valid</code><span class="sig-paren">(</span><em>data</em>, <em>label=None</em>, <em>weight=None</em>, <em>group=None</em>, <em>init_score=None</em>, <em>silent=False</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.create_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.create_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Create validation data align with current Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>string</em><em>, </em><em>numpy array</em><em> or </em><em>scipy.sparse</em>) – Data source of Dataset.
If string, it represents the path to txt file.</li>
<li><strong>label</strong> (<em>list</em><em> or </em><em>numpy 1-D array</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Label of the training data.</li>
<li><strong>weight</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weight for each instance.</li>
<li><strong>group</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group/query size for Dataset.</li>
<li><strong>init_score</strong> (<em>list</em><em>, </em><em>numpy 1-D array</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score for Dataset.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to print messages during construction.</li>
<li><strong>params</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Other parameters.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>valid</strong> – Validation Dataset with reference to self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_field">
<code class="descname">get_field</code><span class="sig-paren">(</span><em>field_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_field"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_field" title="Permalink to this definition">¶</a></dt>
<dd><p>Get property from the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>field_name</strong> (<em>string</em>) – The field name of the information.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>info</strong> – A numpy array with information from the Dataset.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_group">
<code class="descname">get_group</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_group"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_group" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the group of the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>group</strong> – Group size of each group.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy array or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_init_score">
<code class="descname">get_init_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_init_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_init_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the initial score of the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>init_score</strong> – Init score of Booster.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy array or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_label">
<code class="descname">get_label</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_label"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the label of the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>label</strong> – The label information from the Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy array or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_ref_chain">
<code class="descname">get_ref_chain</code><span class="sig-paren">(</span><em>ref_limit=100</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_ref_chain"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_ref_chain" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a chain of Dataset objects, starting with r, then going to r.reference if exists,
then to r.reference.reference, etc. until we hit <code class="docutils literal notranslate"><span class="pre">ref_limit</span></code> or a reference loop.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>ref_limit</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – The limit number of references.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>ref_chain</strong> – Chain of references of the Datasets.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">set of Dataset</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.get_weight">
<code class="descname">get_weight</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.get_weight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.get_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the weight of the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>weight</strong> – Weight for each data point from the Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy array or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.num_data">
<code class="descname">num_data</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.num_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.num_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the number of rows in the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>number_of_rows</strong> – The number of rows in the Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.num_feature">
<code class="descname">num_feature</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.num_feature"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.num_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the number of columns (features) in the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>number_of_columns</strong> – The number of columns (features) in the Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.save_binary">
<code class="descname">save_binary</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.save_binary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.save_binary" title="Permalink to this definition">¶</a></dt>
<dd><p>Save Dataset to binary file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filename</strong> (<em>string</em>) – Name of the output file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Returns self.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_categorical_feature">
<code class="descname">set_categorical_feature</code><span class="sig-paren">(</span><em>categorical_feature</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_categorical_feature"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_categorical_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Set categorical features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>categorical_feature</strong> (<em>list of int</em><em> or </em><em>strings</em>) – Names or indices of categorical features.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set categorical features.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_feature_name">
<code class="descname">set_feature_name</code><span class="sig-paren">(</span><em>feature_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_feature_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_feature_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Set feature name.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>feature_name</strong> (<em>list of strings</em>) – Feature names.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set feature name.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_field">
<code class="descname">set_field</code><span class="sig-paren">(</span><em>field_name</em>, <em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_field"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_field" title="Permalink to this definition">¶</a></dt>
<dd><p>Set property into the Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>field_name</strong> (<em>string</em>) – The field name of the information.</li>
<li><strong>data</strong> (<em>list</em><em>, </em><em>numpy array</em><em> or </em><em>None</em>) – The array of data to be set.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Dataset with set property.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_group">
<code class="descname">set_group</code><span class="sig-paren">(</span><em>group</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_group"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_group" title="Permalink to this definition">¶</a></dt>
<dd><p>Set group size of Dataset (used for ranking).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>group</strong> (<em>list</em><em>, </em><em>numpy array</em><em> or </em><em>None</em>) – Group size of each group.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set group.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_init_score">
<code class="descname">set_init_score</code><span class="sig-paren">(</span><em>init_score</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_init_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_init_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Set init score of Booster to start from.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>init_score</strong> (<em>list</em><em>, </em><em>numpy array</em><em> or </em><em>None</em>) – Init score for Booster.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set init score.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_label">
<code class="descname">set_label</code><span class="sig-paren">(</span><em>label</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_label"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Set label of Dataset</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>label</strong> (<em>list</em><em>, </em><em>numpy array</em><em> or </em><em>None</em>) – The label information to be set into Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set label.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_reference">
<code class="descname">set_reference</code><span class="sig-paren">(</span><em>reference</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_reference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_reference" title="Permalink to this definition">¶</a></dt>
<dd><p>Set reference Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>reference</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a>) – Reference that is used as a template to consturct the current Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set reference.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.set_weight">
<code class="descname">set_weight</code><span class="sig-paren">(</span><em>weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.set_weight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.set_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Set weight of each instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>weight</strong> (<em>list</em><em>, </em><em>numpy array</em><em> or </em><em>None</em>) – Weight to be set for each data point.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Dataset with set weight.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Dataset.subset">
<code class="descname">subset</code><span class="sig-paren">(</span><em>used_indices</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Dataset.subset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Dataset.subset" title="Permalink to this definition">¶</a></dt>
<dd><p>Get subset of current Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>used_indices</strong> (<em>list of int</em>) – Indices used to create the subset.</li>
<li><strong>params</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Other parameters.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>subset</strong> – Subset of the current Dataset.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset">Dataset</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lightgbm.Booster">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">Booster</code><span class="sig-paren">(</span><em>params=None</em>, <em>train_set=None</em>, <em>model_file=None</em>, <em>silent=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Booster in LightGBM.</p>
<p>Initialize the Booster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>params</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Parameters for Booster.</li>
<li><strong>train_set</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Training dataset.</li>
<li><strong>model_file</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Path to the model file.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to print messages during construction.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lightgbm.Booster.add_valid">
<code class="descname">add_valid</code><span class="sig-paren">(</span><em>data</em>, <em>name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.add_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.add_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Add validation data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a>) – Validation data.</li>
<li><strong>name</strong> (<em>string</em>) – Name of validation data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Booster with set validation data.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.attr">
<code class="descname">attr</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Get attribute string from the Booster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>key</strong> (<em>string</em>) – The name of the attribute.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>value</strong> – The attribute value.
Returns None if attribute does not exist.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">string or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.current_iteration">
<code class="descname">current_iteration</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.current_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.current_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the index of the current iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>cur_iter</strong> – The index of the current iteration.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.dump_model">
<code class="descname">dump_model</code><span class="sig-paren">(</span><em>num_iteration=None</em>, <em>start_iteration=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.dump_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.dump_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Dump Booster to JSON format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Index of the iteration that should be dumped.
If None, if the best iteration exists, it is dumped; otherwise, all iterations are dumped.
If &lt;= 0, all iterations are dumped.</li>
<li><strong>start_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Start index of the iteration that should be dumped.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>json_repr</strong> – JSON format of Booster.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.eval">
<code class="descname">eval</code><span class="sig-paren">(</span><em>data</em>, <em>name</em>, <em>feval=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a>) – Data for the evaluating.</li>
<li><strong>name</strong> (<em>string</em>) – Name of the data.</li>
<li><strong>feval</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized evaluation function.
Should accept two parameters: preds, train_data.
For multi-class task, the preds is group by class_id first, then group by row_id.
If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>result</strong> – List with evaluation results.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.eval_train">
<code class="descname">eval_train</code><span class="sig-paren">(</span><em>feval=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.eval_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.eval_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate for training data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>feval</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized evaluation function.
Should accept two parameters: preds, train_data.
For multi-class task, the preds is group by class_id first, then group by row_id.
If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>result</strong> – List with evaluation results.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.eval_valid">
<code class="descname">eval_valid</code><span class="sig-paren">(</span><em>feval=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.eval_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.eval_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate for validation data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>feval</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized evaluation function.
Should accept two parameters: preds, train_data.
For multi-class task, the preds is group by class_id first, then group by row_id.
If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>result</strong> – List with evaluation results.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.feature_importance">
<code class="descname">feature_importance</code><span class="sig-paren">(</span><em>importance_type='split'</em>, <em>iteration=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.feature_importance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.feature_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>Get feature importances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;split&quot;</em><em>)</em>) – How the importance is calculated.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>result</strong> – Array with feature importances.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.feature_name">
<code class="descname">feature_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.feature_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.feature_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Get names of features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>result</strong> – List with names of features.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.free_dataset">
<code class="descname">free_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.free_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.free_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Free Booster’s Datasets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster without Datasets.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.free_network">
<code class="descname">free_network</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.free_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.free_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Free Booster’s network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with freed network.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.get_leaf_output">
<code class="descname">get_leaf_output</code><span class="sig-paren">(</span><em>tree_id</em>, <em>leaf_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.get_leaf_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.get_leaf_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output of a leaf.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>tree_id</strong> (<em>int</em>) – The index of the tree.</li>
<li><strong>leaf_id</strong> (<em>int</em>) – The index of the leaf in the tree.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>result</strong> – The output of the leaf.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.model_from_string">
<code class="descname">model_from_string</code><span class="sig-paren">(</span><em>model_str</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.model_from_string"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.model_from_string" title="Permalink to this definition">¶</a></dt>
<dd><p>Load Booster from a string.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model_str</strong> (<em>string</em>) – Model will be loaded from this string.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print messages while loading model.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Loaded Booster object.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.model_to_string">
<code class="descname">model_to_string</code><span class="sig-paren">(</span><em>num_iteration=None</em>, <em>start_iteration=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.model_to_string"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.model_to_string" title="Permalink to this definition">¶</a></dt>
<dd><p>Save Booster to string.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Index of the iteration that should be saved.
If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.
If &lt;= 0, all iterations are saved.</li>
<li><strong>start_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Start index of the iteration that should be saved.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>str_repr</strong> – String representation of Booster.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">string</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.num_feature">
<code class="descname">num_feature</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.num_feature"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.num_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Get number of features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>num_feature</strong> – The number of features.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.num_model_per_iteration">
<code class="descname">num_model_per_iteration</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.num_model_per_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.num_model_per_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Get number of models per iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>model_per_iter</strong> – The number of models per iteration.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.num_trees">
<code class="descname">num_trees</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.num_trees"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.num_trees" title="Permalink to this definition">¶</a></dt>
<dd><p>Get number of weak sub-models.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>num_trees</strong> – The number of weak sub-models.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>data</em>, <em>num_iteration=None</em>, <em>raw_score=False</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>data_has_header=False</em>, <em>is_reshape=True</em>, <em>pred_parameter=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a prediction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>string</em><em>, </em><em>numpy array</em><em> or </em><em>scipy.sparse</em>) – Data source for prediction.
If string, it represents the path to txt file.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all iterations are used.
If &lt;= 0, all iterations are used (no limits).</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>data_has_header</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether the data has header.
Used only if data is string.</li>
<li><strong>is_reshape</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, result is reshaped to [nrow, ncol].</li>
<li><strong>pred_parameter</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Deprecated.
Other parameters for the prediction.</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>result</strong> – Prediction result.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.refit">
<code class="descname">refit</code><span class="sig-paren">(</span><em>data</em>, <em>label</em>, <em>decay_rate=0.9</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.refit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.refit" title="Permalink to this definition">¶</a></dt>
<dd><p>Refit the existing Booster by new data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>string</em><em>, </em><em>numpy array</em><em> or </em><em>scipy.sparse</em>) – Data source for refit.
If string, it represents the path to txt file.</li>
<li><strong>label</strong> (<em>list</em><em> or </em><em>numpy 1-D array</em>) – Label for refit.</li>
<li><strong>decay_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – Decay rate of refit, will use <code class="docutils literal notranslate"><span class="pre">leaf_output</span> <span class="pre">=</span> <span class="pre">decay_rate</span> <span class="pre">*</span> <span class="pre">old_leaf_output</span> <span class="pre">+</span> <span class="pre">(1.0</span> <span class="pre">-</span> <span class="pre">decay_rate)</span> <span class="pre">*</span> <span class="pre">new_leaf_output</span></code> to refit trees.</li>
<li><strong>**kwargs</strong> (<em>other parameters for refit</em>) – These parameters will be passed to <code class="docutils literal notranslate"><span class="pre">predict</span></code> method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>result</strong> – Refitted Booster.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.reset_parameter">
<code class="descname">reset_parameter</code><span class="sig-paren">(</span><em>params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.reset_parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.reset_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters of Booster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>params</strong> (<em>dict</em>) – New parameters for Booster.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with new parameters.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.rollback_one_iter">
<code class="descname">rollback_one_iter</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.rollback_one_iter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.rollback_one_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>Rollback one iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with rolled back one iteration.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.save_model">
<code class="descname">save_model</code><span class="sig-paren">(</span><em>filename</em>, <em>num_iteration=None</em>, <em>start_iteration=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.save_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Save Booster to file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>filename</strong> (<em>string</em>) – Filename to save Booster.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Index of the iteration that should be saved.
If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.
If &lt;= 0, all iterations are saved.</li>
<li><strong>start_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Start index of the iteration that should be saved.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Returns self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.set_attr">
<code class="descname">set_attr</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.set_attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.set_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the attribute of the Booster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>**kwargs</strong> – The attributes to set.
Setting a value to None deletes an attribute.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with set attribute.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.set_network">
<code class="descname">set_network</code><span class="sig-paren">(</span><em>machines</em>, <em>local_listen_port=12400</em>, <em>listen_time_out=120</em>, <em>num_machines=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.set_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.set_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the network configuration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>machines</strong> (<em>list</em><em>, </em><em>set</em><em> or </em><em>string</em>) – Names of machines.</li>
<li><strong>local_listen_port</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=12400</em><em>)</em>) – TCP listen port for local machines.</li>
<li><strong>listen_time_out</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=120</em><em>)</em>) – Socket time-out in minutes.</li>
<li><strong>num_machines</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The number of machines for parallel learning application.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Booster with set network.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.set_train_data_name">
<code class="descname">set_train_data_name</code><span class="sig-paren">(</span><em>name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.set_train_data_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.set_train_data_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the name to the training Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name</strong> (<em>string</em>) – Name for the training Dataset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with set training Dataset name.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.shuffle_models">
<code class="descname">shuffle_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.shuffle_models"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.shuffle_models" title="Permalink to this definition">¶</a></dt>
<dd><p>Shuffle models.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> – Booster with shuffled models.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.Booster.update">
<code class="descname">update</code><span class="sig-paren">(</span><em>train_set=None</em>, <em>fobj=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/basic.html#Booster.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.Booster.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update Booster for one iteration.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>train_set</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Training data.
If None, last training data is used.</li>
<li><strong>fobj</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – <p>Customized objective function.</p>
<p>For multi-class task, the score is group by class_id first, then group by row_id.
If you want to get i-th row score in j-th class, the access way is score[j * num_data + i]
and you should group grad and hess in this way as well.</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>is_finished</strong> – Whether the update was successfully finished.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">bool</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="training-api">
<h2>Training API<a class="headerlink" href="#training-api" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="lightgbm.train">
<code class="descclassname">lightgbm.</code><code class="descname">train</code><span class="sig-paren">(</span><em>params</em>, <em>train_set</em>, <em>num_boost_round=100</em>, <em>valid_sets=None</em>, <em>valid_names=None</em>, <em>fobj=None</em>, <em>feval=None</em>, <em>init_model=None</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>early_stopping_rounds=None</em>, <em>evals_result=None</em>, <em>verbose_eval=True</em>, <em>learning_rates=None</em>, <em>keep_training_booster=False</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/engine.html#train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the training with given parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>params</strong> (<em>dict</em>) – Parameters for training.</li>
<li><strong>train_set</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a>) – Data to be trained.</li>
<li><strong>num_boost_round</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosting iterations.</li>
<li><strong>valid_sets</strong> (<em>list of Datasets</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of data to be evaluated during training.</li>
<li><strong>valid_names</strong> (<em>list of string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Names of <code class="docutils literal notranslate"><span class="pre">valid_sets</span></code>.</li>
<li><strong>fobj</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized objective function.</li>
<li><strong>feval</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized evaluation function.
Should accept two parameters: preds, train_data.
For multi-class task, the preds is group by class_id first, then group by row_id.
If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.
To ignore the default metric corresponding to the used objective,
set the <code class="docutils literal notranslate"><span class="pre">metric</span></code> parameter to the string <code class="docutils literal notranslate"><span class="pre">&quot;None&quot;</span></code> in <code class="docutils literal notranslate"><span class="pre">params</span></code>.</li>
<li><strong>init_model</strong> (<em>string</em><em>, </em><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster"><em>Booster</em></a><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Filename of LightGBM model or Booster instance used for continue training.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping. The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.
If early stopping occurs, the model will add <code class="docutils literal notranslate"><span class="pre">best_iteration</span></code> field.</li>
<li><strong>evals_result</strong> (<em>dict</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – <p>This dictionary used to store all evaluation results of all the items in <code class="docutils literal notranslate"><span class="pre">valid_sets</span></code>.</p>
<p class="rubric">Example</p>
<p>With a <code class="docutils literal notranslate"><span class="pre">valid_sets</span></code> = [valid_set, train_set],
<code class="docutils literal notranslate"><span class="pre">valid_names</span></code> = [‘eval’, ‘train’]
and a <code class="docutils literal notranslate"><span class="pre">params</span></code> = (‘metric’:’logloss’)
returns: {‘train’: {‘logloss’: [‘0.48253’, ‘0.35953’, …]},
‘eval’: {‘logloss’: [‘0.480385’, ‘0.357756’, …]}}.</p>
</li>
<li><strong>verbose_eval</strong> (<em>bool</em><em> or </em><em>int</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – <p>Requires at least one validation data.
If True, the eval metric on the valid set is printed at each boosting stage.
If int, the eval metric on the valid set is printed at every <code class="docutils literal notranslate"><span class="pre">verbose_eval</span></code> boosting stage.
The last boosting stage or the boosting stage found by using <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> is also printed.</p>
<p class="rubric">Example</p>
<p>With <code class="docutils literal notranslate"><span class="pre">verbose_eval</span></code> = 4 and at least one item in evals,
an evaluation metric is printed every 4 (instead of 1) boosting stages.</p>
</li>
<li><strong>learning_rates</strong> (<em>list</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of learning rates for each boosting round
or a customized function that calculates <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>
in terms of current number of round (e.g. yields learning rate decay).</li>
<li><strong>keep_training_booster</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether the returned Booster will be used to keep training.
If False, the returned value will be converted into _InnerPredictor before returning.
You can still use _InnerPredictor as <code class="docutils literal notranslate"><span class="pre">init_model</span></code> for future continue training.</li>
<li><strong>callbacks</strong> (<em>list of callables</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>booster</strong> – The trained Booster model.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster">Booster</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.cv">
<code class="descclassname">lightgbm.</code><code class="descname">cv</code><span class="sig-paren">(</span><em>params</em>, <em>train_set</em>, <em>num_boost_round=100</em>, <em>folds=None</em>, <em>nfold=5</em>, <em>stratified=True</em>, <em>shuffle=True</em>, <em>metrics=None</em>, <em>fobj=None</em>, <em>feval=None</em>, <em>init_model=None</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>early_stopping_rounds=None</em>, <em>fpreproc=None</em>, <em>verbose_eval=None</em>, <em>show_stdv=True</em>, <em>seed=0</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/engine.html#cv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.cv" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the cross-validation with given paramaters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>params</strong> (<em>dict</em>) – Parameters for Booster.</li>
<li><strong>train_set</strong> (<a class="reference internal" href="#lightgbm.Dataset" title="lightgbm.Dataset"><em>Dataset</em></a>) – Data to be trained on.</li>
<li><strong>num_boost_round</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosting iterations.</li>
<li><strong>folds</strong> (<em>a generator</em><em> or </em><em>iterator of</em><em> (</em><em>train_idx</em><em>, </em><em>test_idx</em><em>) </em><em>tuples</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The train and test indices for the each fold.
This argument has highest priority over other data split arguments.</li>
<li><strong>nfold</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em>) – Number of folds in CV.</li>
<li><strong>stratified</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to perform stratified sampling.</li>
<li><strong>shuffle</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to shuffle before splitting data.</li>
<li><strong>metrics</strong> (<em>string</em><em>, </em><em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Evaluation metrics to be monitored while CV.
If not None, the metric in <code class="docutils literal notranslate"><span class="pre">params</span></code> will be overridden.</li>
<li><strong>fobj</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Custom objective function.</li>
<li><strong>feval</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Customized evaluation function.
Should accept two parameters: preds, train_data.
For multi-class task, the preds is group by class_id first, then group by row_id.
If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.
To ignore the default metric corresponding to the used objective,
set <code class="docutils literal notranslate"><span class="pre">metrics</span></code> to the string <code class="docutils literal notranslate"><span class="pre">&quot;None&quot;</span></code>.</li>
<li><strong>init_model</strong> (<em>string</em><em>, </em><a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster"><em>Booster</em></a><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Filename of LightGBM model or Booster instance used for continue training.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping.
CV score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue.
Requires at least one metric. If there’s more than one, will check all of them.
Last entry in evaluation history is the one from best iteration.</li>
<li><strong>fpreproc</strong> (<em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Preprocessing function that takes (dtrain, dtest, params)
and returns transformed versions of those.</li>
<li><strong>verbose_eval</strong> (<em>bool</em><em>, </em><em>int</em><em>, or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Whether to display the progress.
If None, progress will be displayed when np.ndarray is returned.
If True, progress will be displayed at every boosting stage.
If int, progress will be displayed at every given <code class="docutils literal notranslate"><span class="pre">verbose_eval</span></code> boosting stage.</li>
<li><strong>show_stdv</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to display the standard deviation in progress.
Results are not affected by this parameter, and always contains std.</li>
<li><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Seed used to generate the folds (passed to numpy.random.seed).</li>
<li><strong>callbacks</strong> (<em>list of callables</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>eval_hist</strong> – Evaluation history.
The dictionary has the following format:
{‘metric1-mean’: [values], ‘metric1-stdv’: [values],
‘metric2-mean’: [values], ‘metric2-stdv’: [values],
…}.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="scikit-learn-api">
<h2>Scikit-learn API<a class="headerlink" href="#scikit-learn-api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lightgbm.LGBMModel">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">LGBMModel</code><span class="sig-paren">(</span><em>boosting_type='gbdt'</em>, <em>num_leaves=31</em>, <em>max_depth=-1</em>, <em>learning_rate=0.1</em>, <em>n_estimators=100</em>, <em>subsample_for_bin=200000</em>, <em>objective=None</em>, <em>class_weight=None</em>, <em>min_split_gain=0.0</em>, <em>min_child_weight=0.001</em>, <em>min_child_samples=20</em>, <em>subsample=1.0</em>, <em>subsample_freq=0</em>, <em>colsample_bytree=1.0</em>, <em>reg_alpha=0.0</em>, <em>reg_lambda=0.0</em>, <em>random_state=None</em>, <em>n_jobs=-1</em>, <em>silent=True</em>, <em>importance_type='split'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implementation of the scikit-learn API for LightGBM.</p>
<p>Construct a gradient boosting model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>boosting_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;gbdt&quot;</em><em>)</em>) – ‘gbdt’, traditional Gradient Boosting Decision Tree.
‘dart’, Dropouts meet Multiple Additive Regression Trees.
‘goss’, Gradient-based One-Side Sampling.
‘rf’, Random Forest.</li>
<li><strong>num_leaves</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=31</em><em>)</em>) – Maximum tree leaves for base learners.</li>
<li><strong>max_depth</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Maximum tree depth for base learners, -1 means no limit.</li>
<li><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Boosting learning rate.
You can use <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to shrink/adapt learning rate
in training using <code class="docutils literal notranslate"><span class="pre">reset_parameter</span></code> callback.
Note, that this will ignore the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> argument in training.</li>
<li><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosted trees to fit.</li>
<li><strong>subsample_for_bin</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=50000</em><em>)</em>) – Number of samples for constructing bins.</li>
<li><strong>objective</strong> (<em>string</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).
Default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.</li>
<li><strong>class_weight</strong> (<em>dict</em><em>, </em><em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
Use this parameter only for multi-class classification task;
for binary classification task you may use <code class="docutils literal notranslate"><span class="pre">is_unbalance</span></code> or <code class="docutils literal notranslate"><span class="pre">scale_pos_weight</span></code> parameters.
The ‘balanced’ mode uses the values of y to automatically adjust weights
inversely proportional to class frequencies in the input data as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>.
If None, all classes are supposed to have weight one.
Note that these weights will be multiplied with <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> (passed through the fit method)
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is specified.</li>
<li><strong>min_split_gain</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – Minimum loss reduction required to make a further partition on a leaf node of the tree.</li>
<li><strong>min_child_weight</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-3</em><em>)</em>) – Minimum sum of instance weight(hessian) needed in a child(leaf).</li>
<li><strong>min_child_samples</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Minimum number of data need in a child(leaf).</li>
<li><strong>subsample</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of the training instance.</li>
<li><strong>subsample_freq</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Frequence of subsample, &lt;=0 means no enable.</li>
<li><strong>colsample_bytree</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of columns when constructing each tree.</li>
<li><strong>reg_alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L1 regularization term on weights.</li>
<li><strong>reg_lambda</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L2 regularization term on weights.</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Random number seed.
If None, default seeds in C++ code will be used.</li>
<li><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Number of parallel threads.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print messages while running boosting.</li>
<li><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='split'</em><em>)</em>) – The type of feature importance to be filled into <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – <p>Check <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Parameters.html">http://lightgbm.readthedocs.io/en/latest/Parameters.html</a> for more parameters.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">**kwargs is not supported in sklearn, it may cause unexpected issues.</p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="lightgbm.LGBMModel.n_features_">
<code class="descname">n_features_</code><a class="headerlink" href="#lightgbm.LGBMModel.n_features_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.classes_">
<code class="descname">classes_</code><a class="headerlink" href="#lightgbm.LGBMModel.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_classes]</em> – The class label array (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.n_classes_">
<code class="descname">n_classes_</code><a class="headerlink" href="#lightgbm.LGBMModel.n_classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of classes (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.best_score_">
<code class="descname">best_score_</code><a class="headerlink" href="#lightgbm.LGBMModel.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.best_iteration_">
<code class="descname">best_iteration_</code><a class="headerlink" href="#lightgbm.LGBMModel.best_iteration_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int or None</em> – The best iteration of fitted model if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.objective_">
<code class="descname">objective_</code><a class="headerlink" href="#lightgbm.LGBMModel.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>string or callable</em> – The concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.booster_">
<code class="descname">booster_</code><a class="headerlink" href="#lightgbm.LGBMModel.booster_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Booster</em> – The underlying Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.evals_result_">
<code class="descname">evals_result_</code><a class="headerlink" href="#lightgbm.LGBMModel.evals_result_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The evaluation results if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMModel.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#lightgbm.LGBMModel.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_features]</em> – The feature importances (the higher, the more important the feature).</p>
</dd></dl>

<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code> or
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">group)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The predicted values.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>grad <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the gradient for each sample point.</dd>
<dt>hess <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the second derivative for each sample point.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
and you should group grad and hess in this way as well.</p>
</div>
<dl class="method">
<dt id="lightgbm.LGBMModel.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em>, <em>num_iteration=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMModel.apply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMModel.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted leaf every tree for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>num_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Limit number of iterations in the prediction; defaults to 0 (use all trees).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_leaves</strong> – The predicted leaf every tree for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like of shape = [n_samples, n_trees]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_iteration_</code></dt>
<dd><p>Get the best iteration of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_score_</code></dt>
<dd><p>Get the best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">booster_</code></dt>
<dd><p>Get the underlying lightgbm Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">evals_result_</code></dt>
<dd><p>Get the evaluation results.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">feature_importances_</code></dt>
<dd><p>Get feature importances.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Feature importance in sklearn interface used to normalize to 1,
it’s deprecated after 2.0.4 and is the same as Booster.feature_importance() now.
<code class="docutils literal notranslate"><span class="pre">importance_type</span></code> attribute is passed to the function
to configure the type of importance values to be extracted.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMModel.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>init_score=None</em>, <em>group=None</em>, <em>eval_set=None</em>, <em>eval_names=None</em>, <em>eval_sample_weight=None</em>, <em>eval_class_weight=None</em>, <em>eval_init_score=None</em>, <em>eval_group=None</em>, <em>eval_metric=None</em>, <em>early_stopping_rounds=None</em>, <em>verbose=True</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a gradient boosting model from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input feature matrix.</li>
<li><strong>y</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>]</em>) – The target values (class labels in classification, real numbers in regression).</li>
<li><strong>sample_weight</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of training data.</li>
<li><strong>init_score</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of training data.</li>
<li><strong>group</strong> (<em>array-like</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of training data.</li>
<li><strong>eval_set</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – A list of (X, y) tuple pairs to use as a validation sets.</li>
<li><strong>eval_names</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Names of eval_set.</li>
<li><strong>eval_sample_weight</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of eval data.</li>
<li><strong>eval_class_weight</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Class weights of eval data.</li>
<li><strong>eval_init_score</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of eval data.</li>
<li><strong>eval_group</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of eval data.</li>
<li><strong>eval_metric</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If string, it should be a built-in evaluation metric to use.
If callable, it should be a custom evaluation metric, see note below for more details.
In either case, the <code class="docutils literal notranslate"><span class="pre">metric</span></code> from the model parameters will be evaluated and used as well.
Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping. The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True and an evaluation set is used, writes the evaluation progress.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>callbacks</strong> (<em>list of callback functions</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Returns self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">object</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Custom eval function expects a callable with following functions:
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred)</span></code>, <code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight)</span></code> or
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight,</span> <span class="pre">group)</span></code>.
Returns (eval_name, eval_result, is_bigger_better) or
list of (eval_name, eval_result, is_bigger_better)</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)</span></dt>
<dd>The predicted values.</dd>
<dt>weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The weight of samples.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>eval_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The name of evaluation.</dd>
<dt>eval_result <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The eval result.</dd>
<dt>is_bigger_better <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Is eval result bigger better, e.g. AUC is bigger_better.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].</p>
</div>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">n_features_</code></dt>
<dd><p>Get the number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">objective_</code></dt>
<dd><p>Get the concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMModel.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>raw_score=False</em>, <em>num_iteration=None</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted value for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all trees are used.
If &lt;= 0, all trees are used (no limits).</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>predicted_result</strong> (<em>array-like of shape = [n_samples] or shape = [n_samples, n_classes]</em>) – The predicted values.</li>
<li><strong>X_leaves</strong> (<em>array-like of shape = [n_samples, n_trees] or shape [n_samples, n_trees * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_leaf=True</span></code>, the predicted leaf every tree for each sample.</li>
<li><strong>X_SHAP_values</strong> (<em>array-like of shape = [n_samples, n_features + 1] or shape [n_samples, (n_features + 1) * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_contrib=True</span></code>, the each feature contributions for each sample.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lightgbm.LGBMClassifier">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">LGBMClassifier</code><span class="sig-paren">(</span><em>boosting_type='gbdt'</em>, <em>num_leaves=31</em>, <em>max_depth=-1</em>, <em>learning_rate=0.1</em>, <em>n_estimators=100</em>, <em>subsample_for_bin=200000</em>, <em>objective=None</em>, <em>class_weight=None</em>, <em>min_split_gain=0.0</em>, <em>min_child_weight=0.001</em>, <em>min_child_samples=20</em>, <em>subsample=1.0</em>, <em>subsample_freq=0</em>, <em>colsample_bytree=1.0</em>, <em>reg_alpha=0.0</em>, <em>reg_lambda=0.0</em>, <em>random_state=None</em>, <em>n_jobs=-1</em>, <em>silent=True</em>, <em>importance_type='split'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">lightgbm.sklearn.LGBMModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>LightGBM classifier.</p>
<p>Construct a gradient boosting model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>boosting_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;gbdt&quot;</em><em>)</em>) – ‘gbdt’, traditional Gradient Boosting Decision Tree.
‘dart’, Dropouts meet Multiple Additive Regression Trees.
‘goss’, Gradient-based One-Side Sampling.
‘rf’, Random Forest.</li>
<li><strong>num_leaves</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=31</em><em>)</em>) – Maximum tree leaves for base learners.</li>
<li><strong>max_depth</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Maximum tree depth for base learners, -1 means no limit.</li>
<li><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Boosting learning rate.
You can use <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to shrink/adapt learning rate
in training using <code class="docutils literal notranslate"><span class="pre">reset_parameter</span></code> callback.
Note, that this will ignore the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> argument in training.</li>
<li><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosted trees to fit.</li>
<li><strong>subsample_for_bin</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=50000</em><em>)</em>) – Number of samples for constructing bins.</li>
<li><strong>objective</strong> (<em>string</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).
Default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.</li>
<li><strong>class_weight</strong> (<em>dict</em><em>, </em><em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
Use this parameter only for multi-class classification task;
for binary classification task you may use <code class="docutils literal notranslate"><span class="pre">is_unbalance</span></code> or <code class="docutils literal notranslate"><span class="pre">scale_pos_weight</span></code> parameters.
The ‘balanced’ mode uses the values of y to automatically adjust weights
inversely proportional to class frequencies in the input data as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>.
If None, all classes are supposed to have weight one.
Note that these weights will be multiplied with <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> (passed through the fit method)
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is specified.</li>
<li><strong>min_split_gain</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – Minimum loss reduction required to make a further partition on a leaf node of the tree.</li>
<li><strong>min_child_weight</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-3</em><em>)</em>) – Minimum sum of instance weight(hessian) needed in a child(leaf).</li>
<li><strong>min_child_samples</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Minimum number of data need in a child(leaf).</li>
<li><strong>subsample</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of the training instance.</li>
<li><strong>subsample_freq</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Frequence of subsample, &lt;=0 means no enable.</li>
<li><strong>colsample_bytree</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of columns when constructing each tree.</li>
<li><strong>reg_alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L1 regularization term on weights.</li>
<li><strong>reg_lambda</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L2 regularization term on weights.</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Random number seed.
If None, default seeds in C++ code will be used.</li>
<li><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Number of parallel threads.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print messages while running boosting.</li>
<li><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='split'</em><em>)</em>) – The type of feature importance to be filled into <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – <p>Check <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Parameters.html">http://lightgbm.readthedocs.io/en/latest/Parameters.html</a> for more parameters.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">**kwargs is not supported in sklearn, it may cause unexpected issues.</p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.n_features_">
<code class="descname">n_features_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.n_features_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.classes_">
<code class="descname">classes_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_classes]</em> – The class label array (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.n_classes_">
<code class="descname">n_classes_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.n_classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of classes (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.best_score_">
<code class="descname">best_score_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.best_iteration_">
<code class="descname">best_iteration_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.best_iteration_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int or None</em> – The best iteration of fitted model if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.objective_">
<code class="descname">objective_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>string or callable</em> – The concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.booster_">
<code class="descname">booster_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.booster_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Booster</em> – The underlying Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.evals_result_">
<code class="descname">evals_result_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.evals_result_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The evaluation results if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMClassifier.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#lightgbm.LGBMClassifier.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_features]</em> – The feature importances (the higher, the more important the feature).</p>
</dd></dl>

<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code> or
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">group)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The predicted values.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>grad <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the gradient for each sample point.</dd>
<dt>hess <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the second derivative for each sample point.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
and you should group grad and hess in this way as well.</p>
</div>
<dl class="method">
<dt id="lightgbm.LGBMClassifier.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em>, <em>num_iteration=0</em><span class="sig-paren">)</span><a class="headerlink" href="#lightgbm.LGBMClassifier.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted leaf every tree for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>num_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Limit number of iterations in the prediction; defaults to 0 (use all trees).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_leaves</strong> – The predicted leaf every tree for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like of shape = [n_samples, n_trees]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_iteration_</code></dt>
<dd><p>Get the best iteration of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_score_</code></dt>
<dd><p>Get the best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">booster_</code></dt>
<dd><p>Get the underlying lightgbm Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">classes_</code></dt>
<dd><p>Get the class label array.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">evals_result_</code></dt>
<dd><p>Get the evaluation results.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">feature_importances_</code></dt>
<dd><p>Get feature importances.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Feature importance in sklearn interface used to normalize to 1,
it’s deprecated after 2.0.4 and is the same as Booster.feature_importance() now.
<code class="docutils literal notranslate"><span class="pre">importance_type</span></code> attribute is passed to the function
to configure the type of importance values to be extracted.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>init_score=None</em>, <em>eval_set=None</em>, <em>eval_names=None</em>, <em>eval_sample_weight=None</em>, <em>eval_class_weight=None</em>, <em>eval_init_score=None</em>, <em>eval_metric=None</em>, <em>early_stopping_rounds=None</em>, <em>verbose=True</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a gradient boosting model from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input feature matrix.</li>
<li><strong>y</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>]</em>) – The target values (class labels in classification, real numbers in regression).</li>
<li><strong>sample_weight</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of training data.</li>
<li><strong>init_score</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of training data.</li>
<li><strong>group</strong> (<em>array-like</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of training data.</li>
<li><strong>eval_set</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – A list of (X, y) tuple pairs to use as a validation sets.</li>
<li><strong>eval_names</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Names of eval_set.</li>
<li><strong>eval_sample_weight</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of eval data.</li>
<li><strong>eval_class_weight</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Class weights of eval data.</li>
<li><strong>eval_init_score</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of eval data.</li>
<li><strong>eval_group</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of eval data.</li>
<li><strong>eval_metric</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If string, it should be a built-in evaluation metric to use.
If callable, it should be a custom evaluation metric, see note below for more details.
In either case, the <code class="docutils literal notranslate"><span class="pre">metric</span></code> from the model parameters will be evaluated and used as well.
Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping. The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True and an evaluation set is used, writes the evaluation progress.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>callbacks</strong> (<em>list of callback functions</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Returns self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">object</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Custom eval function expects a callable with following functions:
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred)</span></code>, <code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight)</span></code> or
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight,</span> <span class="pre">group)</span></code>.
Returns (eval_name, eval_result, is_bigger_better) or
list of (eval_name, eval_result, is_bigger_better)</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)</span></dt>
<dd>The predicted values.</dd>
<dt>weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The weight of samples.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>eval_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The name of evaluation.</dd>
<dt>eval_result <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The eval result.</dd>
<dt>is_bigger_better <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Is eval result bigger better, e.g. AUC is bigger_better.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].</p>
</div>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">n_classes_</code></dt>
<dd><p>Get the number of classes.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">n_features_</code></dt>
<dd><p>Get the number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">objective_</code></dt>
<dd><p>Get the concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>raw_score=False</em>, <em>num_iteration=None</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted value for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all trees are used.
If &lt;= 0, all trees are used (no limits).</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>predicted_result</strong> (<em>array-like of shape = [n_samples] or shape = [n_samples, n_classes]</em>) – The predicted values.</li>
<li><strong>X_leaves</strong> (<em>array-like of shape = [n_samples, n_trees] or shape [n_samples, n_trees * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_leaf=True</span></code>, the predicted leaf every tree for each sample.</li>
<li><strong>X_SHAP_values</strong> (<em>array-like of shape = [n_samples, n_features + 1] or shape [n_samples, (n_features + 1) * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_contrib=True</span></code>, the each feature contributions for each sample.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>raw_score=False</em>, <em>num_iteration=None</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted probability for each class for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all trees are used.
If &lt;= 0, all trees are used (no limits).</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>predicted_probability</strong> (<em>array-like of shape = [n_samples, n_classes]</em>) – The predicted probability for each class for each sample.</li>
<li><strong>X_leaves</strong> (<em>array-like of shape = [n_samples, n_trees * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_leaf=True</span></code>, the predicted leaf every tree for each sample.</li>
<li><strong>X_SHAP_values</strong> (<em>array-like of shape = [n_samples, (n_features + 1) * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_contrib=True</span></code>, the each feature contributions for each sample.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lightgbm.LGBMRegressor">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">LGBMRegressor</code><span class="sig-paren">(</span><em>boosting_type='gbdt'</em>, <em>num_leaves=31</em>, <em>max_depth=-1</em>, <em>learning_rate=0.1</em>, <em>n_estimators=100</em>, <em>subsample_for_bin=200000</em>, <em>objective=None</em>, <em>class_weight=None</em>, <em>min_split_gain=0.0</em>, <em>min_child_weight=0.001</em>, <em>min_child_samples=20</em>, <em>subsample=1.0</em>, <em>subsample_freq=0</em>, <em>colsample_bytree=1.0</em>, <em>reg_alpha=0.0</em>, <em>reg_lambda=0.0</em>, <em>random_state=None</em>, <em>n_jobs=-1</em>, <em>silent=True</em>, <em>importance_type='split'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">lightgbm.sklearn.LGBMModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>LightGBM regressor.</p>
<p>Construct a gradient boosting model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>boosting_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;gbdt&quot;</em><em>)</em>) – ‘gbdt’, traditional Gradient Boosting Decision Tree.
‘dart’, Dropouts meet Multiple Additive Regression Trees.
‘goss’, Gradient-based One-Side Sampling.
‘rf’, Random Forest.</li>
<li><strong>num_leaves</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=31</em><em>)</em>) – Maximum tree leaves for base learners.</li>
<li><strong>max_depth</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Maximum tree depth for base learners, -1 means no limit.</li>
<li><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Boosting learning rate.
You can use <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to shrink/adapt learning rate
in training using <code class="docutils literal notranslate"><span class="pre">reset_parameter</span></code> callback.
Note, that this will ignore the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> argument in training.</li>
<li><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosted trees to fit.</li>
<li><strong>subsample_for_bin</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=50000</em><em>)</em>) – Number of samples for constructing bins.</li>
<li><strong>objective</strong> (<em>string</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).
Default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.</li>
<li><strong>class_weight</strong> (<em>dict</em><em>, </em><em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
Use this parameter only for multi-class classification task;
for binary classification task you may use <code class="docutils literal notranslate"><span class="pre">is_unbalance</span></code> or <code class="docutils literal notranslate"><span class="pre">scale_pos_weight</span></code> parameters.
The ‘balanced’ mode uses the values of y to automatically adjust weights
inversely proportional to class frequencies in the input data as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>.
If None, all classes are supposed to have weight one.
Note that these weights will be multiplied with <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> (passed through the fit method)
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is specified.</li>
<li><strong>min_split_gain</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – Minimum loss reduction required to make a further partition on a leaf node of the tree.</li>
<li><strong>min_child_weight</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-3</em><em>)</em>) – Minimum sum of instance weight(hessian) needed in a child(leaf).</li>
<li><strong>min_child_samples</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Minimum number of data need in a child(leaf).</li>
<li><strong>subsample</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of the training instance.</li>
<li><strong>subsample_freq</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Frequence of subsample, &lt;=0 means no enable.</li>
<li><strong>colsample_bytree</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of columns when constructing each tree.</li>
<li><strong>reg_alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L1 regularization term on weights.</li>
<li><strong>reg_lambda</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L2 regularization term on weights.</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Random number seed.
If None, default seeds in C++ code will be used.</li>
<li><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Number of parallel threads.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print messages while running boosting.</li>
<li><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='split'</em><em>)</em>) – The type of feature importance to be filled into <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – <p>Check <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Parameters.html">http://lightgbm.readthedocs.io/en/latest/Parameters.html</a> for more parameters.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">**kwargs is not supported in sklearn, it may cause unexpected issues.</p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.n_features_">
<code class="descname">n_features_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.n_features_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.classes_">
<code class="descname">classes_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_classes]</em> – The class label array (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.n_classes_">
<code class="descname">n_classes_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.n_classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of classes (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.best_score_">
<code class="descname">best_score_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.best_iteration_">
<code class="descname">best_iteration_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.best_iteration_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int or None</em> – The best iteration of fitted model if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.objective_">
<code class="descname">objective_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>string or callable</em> – The concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.booster_">
<code class="descname">booster_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.booster_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Booster</em> – The underlying Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.evals_result_">
<code class="descname">evals_result_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.evals_result_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The evaluation results if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRegressor.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#lightgbm.LGBMRegressor.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_features]</em> – The feature importances (the higher, the more important the feature).</p>
</dd></dl>

<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code> or
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">group)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The predicted values.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>grad <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the gradient for each sample point.</dd>
<dt>hess <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the second derivative for each sample point.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
and you should group grad and hess in this way as well.</p>
</div>
<dl class="method">
<dt id="lightgbm.LGBMRegressor.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em>, <em>num_iteration=0</em><span class="sig-paren">)</span><a class="headerlink" href="#lightgbm.LGBMRegressor.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted leaf every tree for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>num_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Limit number of iterations in the prediction; defaults to 0 (use all trees).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_leaves</strong> – The predicted leaf every tree for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like of shape = [n_samples, n_trees]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_iteration_</code></dt>
<dd><p>Get the best iteration of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_score_</code></dt>
<dd><p>Get the best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">booster_</code></dt>
<dd><p>Get the underlying lightgbm Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">evals_result_</code></dt>
<dd><p>Get the evaluation results.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">feature_importances_</code></dt>
<dd><p>Get feature importances.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Feature importance in sklearn interface used to normalize to 1,
it’s deprecated after 2.0.4 and is the same as Booster.feature_importance() now.
<code class="docutils literal notranslate"><span class="pre">importance_type</span></code> attribute is passed to the function
to configure the type of importance values to be extracted.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>init_score=None</em>, <em>eval_set=None</em>, <em>eval_names=None</em>, <em>eval_sample_weight=None</em>, <em>eval_init_score=None</em>, <em>eval_metric=None</em>, <em>early_stopping_rounds=None</em>, <em>verbose=True</em>, <em>feature_name='auto'</em>, <em>categorical_feature='auto'</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a gradient boosting model from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input feature matrix.</li>
<li><strong>y</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>]</em>) – The target values (class labels in classification, real numbers in regression).</li>
<li><strong>sample_weight</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of training data.</li>
<li><strong>init_score</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of training data.</li>
<li><strong>group</strong> (<em>array-like</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of training data.</li>
<li><strong>eval_set</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – A list of (X, y) tuple pairs to use as a validation sets.</li>
<li><strong>eval_names</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Names of eval_set.</li>
<li><strong>eval_sample_weight</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of eval data.</li>
<li><strong>eval_init_score</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of eval data.</li>
<li><strong>eval_group</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of eval data.</li>
<li><strong>eval_metric</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If string, it should be a built-in evaluation metric to use.
If callable, it should be a custom evaluation metric, see note below for more details.
In either case, the <code class="docutils literal notranslate"><span class="pre">metric</span></code> from the model parameters will be evaluated and used as well.
Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping. The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True and an evaluation set is used, writes the evaluation progress.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>callbacks</strong> (<em>list of callback functions</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Returns self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">object</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Custom eval function expects a callable with following functions:
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred)</span></code>, <code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight)</span></code> or
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight,</span> <span class="pre">group)</span></code>.
Returns (eval_name, eval_result, is_bigger_better) or
list of (eval_name, eval_result, is_bigger_better)</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)</span></dt>
<dd>The predicted values.</dd>
<dt>weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The weight of samples.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>eval_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The name of evaluation.</dd>
<dt>eval_result <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The eval result.</dd>
<dt>is_bigger_better <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Is eval result bigger better, e.g. AUC is bigger_better.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].</p>
</div>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">n_features_</code></dt>
<dd><p>Get the number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">objective_</code></dt>
<dd><p>Get the concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>raw_score=False</em>, <em>num_iteration=None</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#lightgbm.LGBMRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted value for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all trees are used.
If &lt;= 0, all trees are used (no limits).</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>predicted_result</strong> (<em>array-like of shape = [n_samples] or shape = [n_samples, n_classes]</em>) – The predicted values.</li>
<li><strong>X_leaves</strong> (<em>array-like of shape = [n_samples, n_trees] or shape [n_samples, n_trees * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_leaf=True</span></code>, the predicted leaf every tree for each sample.</li>
<li><strong>X_SHAP_values</strong> (<em>array-like of shape = [n_samples, n_features + 1] or shape [n_samples, (n_features + 1) * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_contrib=True</span></code>, the each feature contributions for each sample.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lightgbm.LGBMRanker">
<em class="property">class </em><code class="descclassname">lightgbm.</code><code class="descname">LGBMRanker</code><span class="sig-paren">(</span><em>boosting_type='gbdt'</em>, <em>num_leaves=31</em>, <em>max_depth=-1</em>, <em>learning_rate=0.1</em>, <em>n_estimators=100</em>, <em>subsample_for_bin=200000</em>, <em>objective=None</em>, <em>class_weight=None</em>, <em>min_split_gain=0.0</em>, <em>min_child_weight=0.001</em>, <em>min_child_samples=20</em>, <em>subsample=1.0</em>, <em>subsample_freq=0</em>, <em>colsample_bytree=1.0</em>, <em>reg_alpha=0.0</em>, <em>reg_lambda=0.0</em>, <em>random_state=None</em>, <em>n_jobs=-1</em>, <em>silent=True</em>, <em>importance_type='split'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMRanker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMRanker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">lightgbm.sklearn.LGBMModel</span></code></p>
<p>LightGBM ranker.</p>
<p>Construct a gradient boosting model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>boosting_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;gbdt&quot;</em><em>)</em>) – ‘gbdt’, traditional Gradient Boosting Decision Tree.
‘dart’, Dropouts meet Multiple Additive Regression Trees.
‘goss’, Gradient-based One-Side Sampling.
‘rf’, Random Forest.</li>
<li><strong>num_leaves</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=31</em><em>)</em>) – Maximum tree leaves for base learners.</li>
<li><strong>max_depth</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Maximum tree depth for base learners, -1 means no limit.</li>
<li><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Boosting learning rate.
You can use <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to shrink/adapt learning rate
in training using <code class="docutils literal notranslate"><span class="pre">reset_parameter</span></code> callback.
Note, that this will ignore the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> argument in training.</li>
<li><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of boosted trees to fit.</li>
<li><strong>subsample_for_bin</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=50000</em><em>)</em>) – Number of samples for constructing bins.</li>
<li><strong>objective</strong> (<em>string</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).
Default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.</li>
<li><strong>class_weight</strong> (<em>dict</em><em>, </em><em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
Use this parameter only for multi-class classification task;
for binary classification task you may use <code class="docutils literal notranslate"><span class="pre">is_unbalance</span></code> or <code class="docutils literal notranslate"><span class="pre">scale_pos_weight</span></code> parameters.
The ‘balanced’ mode uses the values of y to automatically adjust weights
inversely proportional to class frequencies in the input data as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>.
If None, all classes are supposed to have weight one.
Note that these weights will be multiplied with <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> (passed through the fit method)
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is specified.</li>
<li><strong>min_split_gain</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – Minimum loss reduction required to make a further partition on a leaf node of the tree.</li>
<li><strong>min_child_weight</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-3</em><em>)</em>) – Minimum sum of instance weight(hessian) needed in a child(leaf).</li>
<li><strong>min_child_samples</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Minimum number of data need in a child(leaf).</li>
<li><strong>subsample</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of the training instance.</li>
<li><strong>subsample_freq</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Frequence of subsample, &lt;=0 means no enable.</li>
<li><strong>colsample_bytree</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.</em><em>)</em>) – Subsample ratio of columns when constructing each tree.</li>
<li><strong>reg_alpha</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L1 regularization term on weights.</li>
<li><strong>reg_lambda</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.</em><em>)</em>) – L2 regularization term on weights.</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Random number seed.
If None, default seeds in C++ code will be used.</li>
<li><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Number of parallel threads.</li>
<li><strong>silent</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print messages while running boosting.</li>
<li><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='split'</em><em>)</em>) – The type of feature importance to be filled into <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – <p>Check <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Parameters.html">http://lightgbm.readthedocs.io/en/latest/Parameters.html</a> for more parameters.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">**kwargs is not supported in sklearn, it may cause unexpected issues.</p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="lightgbm.LGBMRanker.n_features_">
<code class="descname">n_features_</code><a class="headerlink" href="#lightgbm.LGBMRanker.n_features_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.classes_">
<code class="descname">classes_</code><a class="headerlink" href="#lightgbm.LGBMRanker.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_classes]</em> – The class label array (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.n_classes_">
<code class="descname">n_classes_</code><a class="headerlink" href="#lightgbm.LGBMRanker.n_classes_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – The number of classes (only for classification problem).</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.best_score_">
<code class="descname">best_score_</code><a class="headerlink" href="#lightgbm.LGBMRanker.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.best_iteration_">
<code class="descname">best_iteration_</code><a class="headerlink" href="#lightgbm.LGBMRanker.best_iteration_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int or None</em> – The best iteration of fitted model if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.objective_">
<code class="descname">objective_</code><a class="headerlink" href="#lightgbm.LGBMRanker.objective_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>string or callable</em> – The concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.booster_">
<code class="descname">booster_</code><a class="headerlink" href="#lightgbm.LGBMRanker.booster_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Booster</em> – The underlying Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.evals_result_">
<code class="descname">evals_result_</code><a class="headerlink" href="#lightgbm.LGBMRanker.evals_result_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict or None</em> – The evaluation results if <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> has been specified.</p>
</dd></dl>

<dl class="attribute">
<dt id="lightgbm.LGBMRanker.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#lightgbm.LGBMRanker.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array of shape = [n_features]</em> – The feature importances (the higher, the more important the feature).</p>
</dd></dl>

<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code> or
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">group)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The predicted values.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>grad <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the gradient for each sample point.</dd>
<dt>hess <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)</span></dt>
<dd>The value of the second derivative for each sample point.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
and you should group grad and hess in this way as well.</p>
</div>
<dl class="method">
<dt id="lightgbm.LGBMRanker.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em>, <em>num_iteration=0</em><span class="sig-paren">)</span><a class="headerlink" href="#lightgbm.LGBMRanker.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted leaf every tree for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>num_iteration</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Limit number of iterations in the prediction; defaults to 0 (use all trees).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_leaves</strong> – The predicted leaf every tree for each sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like of shape = [n_samples, n_trees]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_iteration_</code></dt>
<dd><p>Get the best iteration of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">best_score_</code></dt>
<dd><p>Get the best score of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">booster_</code></dt>
<dd><p>Get the underlying lightgbm Booster of this model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">evals_result_</code></dt>
<dd><p>Get the evaluation results.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">feature_importances_</code></dt>
<dd><p>Get feature importances.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Feature importance in sklearn interface used to normalize to 1,
it’s deprecated after 2.0.4 and is the same as Booster.feature_importance() now.
<code class="docutils literal notranslate"><span class="pre">importance_type</span></code> attribute is passed to the function
to configure the type of importance values to be extracted.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMRanker.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X, y, sample_weight=None, init_score=None, group=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_group=None, eval_metric=None, eval_at=[1], early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/sklearn.html#LGBMRanker.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.LGBMRanker.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a gradient boosting model from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input feature matrix.</li>
<li><strong>y</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>]</em>) – The target values (class labels in classification, real numbers in regression).</li>
<li><strong>sample_weight</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of training data.</li>
<li><strong>init_score</strong> (<em>array-like of shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of training data.</li>
<li><strong>group</strong> (<em>array-like</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of training data.</li>
<li><strong>eval_set</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – A list of (X, y) tuple pairs to use as a validation sets.</li>
<li><strong>eval_names</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Names of eval_set.</li>
<li><strong>eval_sample_weight</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Weights of eval data.</li>
<li><strong>eval_init_score</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Init score of eval data.</li>
<li><strong>eval_group</strong> (<em>list of arrays</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Group data of eval data.</li>
<li><strong>eval_metric</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>callable</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If string, it should be a built-in evaluation metric to use.
If callable, it should be a custom evaluation metric, see note below for more details.
In either case, the <code class="docutils literal notranslate"><span class="pre">metric</span></code> from the model parameters will be evaluated and used as well.
Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker.</li>
<li><strong>eval_at</strong> (<em>list of int</em><em>, </em><em>optional</em><em> (</em><em>default=</em><em>[</em><em>1</em><em>]</em><em>)</em>) – The evaluation positions of the specified metric.</li>
<li><strong>early_stopping_rounds</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Activates early stopping. The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True and an evaluation set is used, writes the evaluation progress.</li>
<li><strong>feature_name</strong> (<em>list of strings</em><em> or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Feature names.
If ‘auto’ and data is pandas DataFrame, data columns names are used.</li>
<li><strong>categorical_feature</strong> (<em>list of strings</em><em> or </em><em>int</em><em>, or </em><em>'auto'</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Categorical features.
If list of int, interpreted as indices.
If list of strings, interpreted as feature names (need to specify <code class="docutils literal notranslate"><span class="pre">feature_name</span></code> as well).
If ‘auto’ and data is pandas DataFrame, pandas categorical columns are used.
All values in categorical features should be less than int32 max value (2147483647).
All negative values in categorical features will be treated as missing values.</li>
<li><strong>callbacks</strong> (<em>list of callback functions</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of callback functions that are applied at each iteration.
See Callbacks in Python API for more information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> – Returns self.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">object</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Custom eval function expects a callable with following functions:
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred)</span></code>, <code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight)</span></code> or
<code class="docutils literal notranslate"><span class="pre">func(y_true,</span> <span class="pre">y_pred,</span> <span class="pre">weight,</span> <span class="pre">group)</span></code>.
Returns (eval_name, eval_result, is_bigger_better) or
list of (eval_name, eval_result, is_bigger_better)</p>
<blockquote>
<div><dl class="docutils">
<dt>y_true <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The target values.</dd>
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)</span></dt>
<dd>The predicted values.</dd>
<dt>weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like of shape = [n_samples]</span></dt>
<dd>The weight of samples.</dd>
<dt>group <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>Group/query data, used for ranking task.</dd>
<dt>eval_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The name of evaluation.</dd>
<dt>eval_result <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The eval result.</dd>
<dt>is_bigger_better <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Is eval result bigger better, e.g. AUC is bigger_better.</dd>
</dl>
</div></blockquote>
<p class="last">For multi-class task, the y_pred is group by class_id first, then group by row_id.
If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].</p>
</div>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">n_features_</code></dt>
<dd><p>Get the number of features of fitted model.</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">objective_</code></dt>
<dd><p>Get the concrete objective used while fitting this model.</p>
</dd></dl>

<dl class="method">
<dt id="lightgbm.LGBMRanker.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>raw_score=False</em>, <em>num_iteration=None</em>, <em>pred_leaf=False</em>, <em>pred_contrib=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#lightgbm.LGBMRanker.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the predicted value for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix of shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</li>
<li><strong>raw_score</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict raw scores.</li>
<li><strong>num_iteration</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Limit number of iterations in the prediction.
If None, if the best iteration exists, it is used; otherwise, all trees are used.
If &lt;= 0, all trees are used (no limits).</li>
<li><strong>pred_leaf</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Whether to predict leaf index.</li>
<li><strong>pred_contrib</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>Whether to predict feature contributions.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you want to get more explanation for your model’s predictions using SHAP values
like SHAP interaction values,
you can install shap package (<a class="reference external" href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>).</p>
</div>
</li>
<li><strong>**kwargs</strong> (<em>other parameters for the prediction</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>predicted_result</strong> (<em>array-like of shape = [n_samples] or shape = [n_samples, n_classes]</em>) – The predicted values.</li>
<li><strong>X_leaves</strong> (<em>array-like of shape = [n_samples, n_trees] or shape [n_samples, n_trees * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_leaf=True</span></code>, the predicted leaf every tree for each sample.</li>
<li><strong>X_SHAP_values</strong> (<em>array-like of shape = [n_samples, n_features + 1] or shape [n_samples, (n_features + 1) * n_classes]</em>) – If <code class="docutils literal notranslate"><span class="pre">pred_contrib=True</span></code>, the each feature contributions for each sample.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="callbacks">
<h2>Callbacks<a class="headerlink" href="#callbacks" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="lightgbm.early_stopping">
<code class="descclassname">lightgbm.</code><code class="descname">early_stopping</code><span class="sig-paren">(</span><em>stopping_rounds</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/callback.html#early_stopping"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.early_stopping" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a callback that activates early stopping.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Activates early stopping.
The model will train until the validation score stops improving.
Validation score needs to improve at least every <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> round(s)
to continue training.
Requires at least one validation data and one metric.
If there’s more than one, will check all of them. But the training data is ignored anyway.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>stopping_rounds</strong> (<em>int</em>) – The possible number of rounds without the trend occurrence.</li>
<li><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to print message with early stopping information.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>callback</strong> – The callback that activates early stopping.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">function</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.print_evaluation">
<code class="descclassname">lightgbm.</code><code class="descname">print_evaluation</code><span class="sig-paren">(</span><em>period=1</em>, <em>show_stdv=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/callback.html#print_evaluation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.print_evaluation" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a callback that prints the evaluation results.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>period</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The period to print the evaluation results.</li>
<li><strong>show_stdv</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to show stdv (if provided).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>callback</strong> – The callback that prints the evaluation results every <code class="docutils literal notranslate"><span class="pre">period</span></code> iteration(s).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">function</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.record_evaluation">
<code class="descclassname">lightgbm.</code><code class="descname">record_evaluation</code><span class="sig-paren">(</span><em>eval_result</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/callback.html#record_evaluation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.record_evaluation" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a callback that records the evaluation history into <code class="docutils literal notranslate"><span class="pre">eval_result</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>eval_result</strong> (<em>dict</em>) – A dictionary to store the evaluation results.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>callback</strong> – The callback that records the evaluation history into the passed dictionary.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">function</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.reset_parameter">
<code class="descclassname">lightgbm.</code><code class="descname">reset_parameter</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/callback.html#reset_parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.reset_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a callback that resets the parameter after the first iteration.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The initial parameter will still take in-effect on first iteration.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>**kwargs</strong> (<em>value should be list</em><em> or </em><em>function</em>) – List of parameters for each boosting round
or a customized function that calculates the parameter in terms of
current number of round (e.g. yields learning rate decay).
If list lst, parameter = lst[current_round].
If function func, parameter = func(current_round).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>callback</strong> – The callback that resets the parameter after the first iteration.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">function</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="plotting">
<h2>Plotting<a class="headerlink" href="#plotting" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="lightgbm.plot_importance">
<code class="descclassname">lightgbm.</code><code class="descname">plot_importance</code><span class="sig-paren">(</span><em>booster</em>, <em>ax=None</em>, <em>height=0.2</em>, <em>xlim=None</em>, <em>ylim=None</em>, <em>title='Feature importance'</em>, <em>xlabel='Feature importance'</em>, <em>ylabel='Features'</em>, <em>importance_type='split'</em>, <em>max_num_features=None</em>, <em>ignore_zero=True</em>, <em>figsize=None</em>, <em>grid=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/plotting.html#plot_importance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.plot_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot model’s feature importances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>booster</strong> (<a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster"><em>Booster</em></a><em> or </em><a class="reference internal" href="#lightgbm.LGBMModel" title="lightgbm.LGBMModel"><em>LGBMModel</em></a>) – Booster or LGBMModel instance which feature importance should be plotted.</li>
<li><strong>ax</strong> (<em>matplotlib.axes.Axes</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Target axes instance.
If None, new figure and axes will be created.</li>
<li><strong>height</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.2</em><em>)</em>) – Bar height, passed to <code class="docutils literal notranslate"><span class="pre">ax.barh()</span></code>.</li>
<li><strong>xlim</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Tuple passed to <code class="docutils literal notranslate"><span class="pre">ax.xlim()</span></code>.</li>
<li><strong>ylim</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Tuple passed to <code class="docutils literal notranslate"><span class="pre">ax.ylim()</span></code>.</li>
<li><strong>title</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;Feature importance&quot;</em><em>)</em>) – Axes title.
If None, title is disabled.</li>
<li><strong>xlabel</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;Feature importance&quot;</em><em>)</em>) – X-axis title label.
If None, title is disabled.</li>
<li><strong>ylabel</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;Features&quot;</em><em>)</em>) – Y-axis title label.
If None, title is disabled.</li>
<li><strong>importance_type</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;split&quot;</em><em>)</em>) – How the importance is calculated.
If “split”, result contains numbers of times the feature is used in a model.
If “gain”, result contains total gains of splits which use the feature.</li>
<li><strong>max_num_features</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Max number of top features displayed on plot.
If None or &lt;1, all features will be displayed.</li>
<li><strong>ignore_zero</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to ignore features with zero importance.</li>
<li><strong>figsize</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Figure size.</li>
<li><strong>grid</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to add a grid for axes.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – Other parameters passed to <code class="docutils literal notranslate"><span class="pre">ax.barh()</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>ax</strong> – The plot with model’s feature importances.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">matplotlib.axes.Axes</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.plot_metric">
<code class="descclassname">lightgbm.</code><code class="descname">plot_metric</code><span class="sig-paren">(</span><em>booster</em>, <em>metric=None</em>, <em>dataset_names=None</em>, <em>ax=None</em>, <em>xlim=None</em>, <em>ylim=None</em>, <em>title='Metric during training'</em>, <em>xlabel='Iterations'</em>, <em>ylabel='auto'</em>, <em>figsize=None</em>, <em>grid=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/plotting.html#plot_metric"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.plot_metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot one metric during training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>booster</strong> (<em>dict</em><em> or </em><a class="reference internal" href="#lightgbm.LGBMModel" title="lightgbm.LGBMModel"><em>LGBMModel</em></a>) – Dictionary returned from <code class="docutils literal notranslate"><span class="pre">lightgbm.train()</span></code> or LGBMModel instance.</li>
<li><strong>metric</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The metric name to plot.
Only one metric supported because different metrics have various scales.
If None, first metric picked from dictionary (according to hashcode).</li>
<li><strong>dataset_names</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – List of the dataset names which are used to calculate metric to plot.
If None, all datasets are used.</li>
<li><strong>ax</strong> (<em>matplotlib.axes.Axes</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Target axes instance.
If None, new figure and axes will be created.</li>
<li><strong>xlim</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Tuple passed to <code class="docutils literal notranslate"><span class="pre">ax.xlim()</span></code>.</li>
<li><strong>ylim</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Tuple passed to <code class="docutils literal notranslate"><span class="pre">ax.ylim()</span></code>.</li>
<li><strong>title</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;Metric during training&quot;</em><em>)</em>) – Axes title.
If None, title is disabled.</li>
<li><strong>xlabel</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;Iterations&quot;</em><em>)</em>) – X-axis title label.
If None, title is disabled.</li>
<li><strong>ylabel</strong> (<em>string</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – Y-axis title label.
If ‘auto’, metric name is used.
If None, title is disabled.</li>
<li><strong>figsize</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Figure size.</li>
<li><strong>grid</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to add a grid for axes.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>ax</strong> – The plot with metric’s history over the training.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">matplotlib.axes.Axes</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.plot_tree">
<code class="descclassname">lightgbm.</code><code class="descname">plot_tree</code><span class="sig-paren">(</span><em>booster</em>, <em>ax=None</em>, <em>tree_index=0</em>, <em>figsize=None</em>, <em>old_graph_attr=None</em>, <em>old_node_attr=None</em>, <em>old_edge_attr=None</em>, <em>show_info=None</em>, <em>precision=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/plotting.html#plot_tree"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.plot_tree" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot specified tree.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It is preferable to use <code class="docutils literal notranslate"><span class="pre">create_tree_digraph()</span></code> because of its lossless quality
and returned objects can be also rendered and displayed directly inside a Jupyter notebook.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>booster</strong> (<a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster"><em>Booster</em></a><em> or </em><a class="reference internal" href="#lightgbm.LGBMModel" title="lightgbm.LGBMModel"><em>LGBMModel</em></a>) – Booster or LGBMModel instance to be plotted.</li>
<li><strong>ax</strong> (<em>matplotlib.axes.Axes</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Target axes instance.
If None, new figure and axes will be created.</li>
<li><strong>tree_index</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – The index of a target tree to plot.</li>
<li><strong>figsize</strong> (<em>tuple of 2 elements</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Figure size.</li>
<li><strong>show_info</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – What information should be shown in nodes.
Possible values of list items: ‘split_gain’, ‘internal_value’, ‘internal_count’, ‘leaf_count’.</li>
<li><strong>precision</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Used to restrict the display of floating point values to a certain precision.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – Other parameters passed to <code class="docutils literal notranslate"><span class="pre">Digraph</span></code> constructor.
Check <a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#digraph">https://graphviz.readthedocs.io/en/stable/api.html#digraph</a> for the full list of supported parameters.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>ax</strong> – The plot with single tree.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">matplotlib.axes.Axes</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lightgbm.create_tree_digraph">
<code class="descclassname">lightgbm.</code><code class="descname">create_tree_digraph</code><span class="sig-paren">(</span><em>booster</em>, <em>tree_index=0</em>, <em>show_info=None</em>, <em>precision=None</em>, <em>old_name=None</em>, <em>old_comment=None</em>, <em>old_filename=None</em>, <em>old_directory=None</em>, <em>old_format=None</em>, <em>old_engine=None</em>, <em>old_encoding=None</em>, <em>old_graph_attr=None</em>, <em>old_node_attr=None</em>, <em>old_edge_attr=None</em>, <em>old_body=None</em>, <em>old_strict=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightgbm/plotting.html#create_tree_digraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lightgbm.create_tree_digraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a digraph representation of specified tree.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For more information please visit
<a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#digraph">https://graphviz.readthedocs.io/en/stable/api.html#digraph</a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>booster</strong> (<a class="reference internal" href="#lightgbm.Booster" title="lightgbm.Booster"><em>Booster</em></a><em> or </em><a class="reference internal" href="#lightgbm.LGBMModel" title="lightgbm.LGBMModel"><em>LGBMModel</em></a>) – Booster or LGBMModel instance.</li>
<li><strong>tree_index</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – The index of a target tree to convert.</li>
<li><strong>show_info</strong> (<em>list of strings</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – What information should be shown in nodes.
Possible values of list items: ‘split_gain’, ‘internal_value’, ‘internal_count’, ‘leaf_count’.</li>
<li><strong>precision</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Used to restrict the display of floating point values to a certain precision.</li>
<li><strong>**kwargs</strong> (<em>other parameters</em>) – Other parameters passed to <code class="docutils literal notranslate"><span class="pre">Digraph</span></code> constructor.
Check <a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#digraph">https://graphviz.readthedocs.io/en/stable/api.html#digraph</a> for the full list of supported parameters.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>graph</strong> – The digraph representation of specified tree.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">graphviz.Digraph</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Parallel-Learning-Guide.html" class="btn btn-neutral float-right" title="Parallel Learning Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Parameters-Tuning.html" class="btn btn-neutral" title="Parameters Tuning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Microsoft Corporation.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/js/script.js"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>