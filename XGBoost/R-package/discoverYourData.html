
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
  <!-- Licensed under the Apache 2.0 License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/open-sans/stylesheet.css" />
  <!-- Licensed under the SIL Open Font License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/source-serif-pro/source-serif-pro.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap.min.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap-theme.min.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <title>Understand your dataset with XGBoost &#8212; xgboost 0.80 documentation</title>
    <link rel="stylesheet" href="../_static/guzzle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <script type="text/javascript" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="XGBoost JVM Package" href="../jvm/index.html" />
    <link rel="prev" title="XGBoost R Tutorial" href="xgboostPresentation.html" />
  
   

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../jvm/index.html" title="XGBoost JVM Package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="xgboostPresentation.html" title="XGBoost R Tutorial"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">xgboost 0.80 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">XGBoost R Package</a> &#187;</li> 
      </ul>
    </div>
    <div class="container-wrapper">

      <div id="mobile-toggle">
        <a href="#"><span class="glyphicon glyphicon-align-justify" aria-hidden="true"></span></a>
      </div>
  <div id="left-column">
    <div class="sphinxsidebar"><a href="
    ../index.html" class="text-logo">XGBoost</a>
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <h2>Table Of Contents</h2>
  </div>
  <div class="sidebar-toc">
    
    
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../build.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Get Started with XGBoost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">XGBoost Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.xgboost.ai">XGBoost User Forum</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu/index.html">GPU support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameter.html">XGBoost Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Python package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">R package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="xgboostPresentation.html">Introduction to XGBoost in R</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Understanding your dataset with XGBoost</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../jvm/index.html">JVM package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../julia.html">Julia package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">CLI interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to XGBoost</a></li>
</ul>

    
  </div>
</div>
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <div id="main-search">
      <form class="form-inline" action="../search.html" method="GET" role="form">
        <div class="input-group">
          <input name="q" type="text" class="form-control" placeholder="Search...">
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div>
      
    </div>
  </div>
        <div id="right-column">
          
          <div role="navigation" aria-label="breadcrumbs navigation">
            <ol class="breadcrumb">
              <li><a href="../index.html">Docs</a></li>
              
                <li><a href="index.html">XGBoost R Package</a></li>
              
              <li>Understand your dataset with XGBoost</li>
            </ol>
          </div>
          
          <div class="document clearer body">
            
  <div class="section" id="understand-your-dataset-with-xgboost">
<span id="understand-your-dataset-with-xgboost"></span><h1>Understand your dataset with XGBoost<a class="headerlink" href="#understand-your-dataset-with-xgboost" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<span id="introduction"></span><h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The purpose of this Vignette is to show you how to use <strong>Xgboost</strong> to discover and understand your own dataset better.</p>
<p>This Vignette is not about predicting anything (see <a class="reference external" href="https://github.com/dmlc/xgboost/blob/master/R-package/vignettes/xgboostPresentation.Rmd">Xgboost presentation</a>). We will explain how to use <strong>Xgboost</strong> to highlight the <em>link</em> between the <em>features</em> of your data and the <em>outcome</em>.</p>
<p>Package loading:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kn">require</span><span class="p">(</span>xgboost<span class="p">)</span>
<span class="kn">require</span><span class="p">(</span>Matrix<span class="p">)</span>
<span class="kn">require</span><span class="p">(</span>data.table<span class="p">)</span>
<span class="kr">if</span> <span class="p">(</span><span class="o">!</span><span class="kn">require</span><span class="p">(</span><span class="s">&#39;vcd&#39;</span><span class="p">))</span> install.packages<span class="p">(</span><span class="s">&#39;vcd&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><strong>VCD</strong> package is used for one of its embedded dataset only.</div></blockquote>
</div>
<div class="section" id="preparation-of-the-dataset">
<span id="preparation-of-the-dataset"></span><h2>Preparation of the dataset<a class="headerlink" href="#preparation-of-the-dataset" title="Permalink to this headline">¶</a></h2>
<div class="section" id="numeric-vs-categorical-variables">
<span id="numeric-vs-categorical-variables"></span><h3>Numeric VS categorical variables<a class="headerlink" href="#numeric-vs-categorical-variables" title="Permalink to this headline">¶</a></h3>
<p><strong>Xgboost</strong> manages only <code class="docutils literal notranslate"><span class="pre">numeric</span></code> vectors.</p>
<p>What to do when you have <em>categorical</em> data?</p>
<p>A <em>categorical</em> variable has a fixed number of different values. For instance, if a variable called <em>Colour</em> can have only one of these three values, <em>red</em>, <em>blue</em> or <em>green</em>, then <em>Colour</em> is a <em>categorical</em> variable.</p>
<blockquote>
<div><p>In <strong>R</strong>, a <em>categorical</em> variable is called <code class="docutils literal notranslate"><span class="pre">factor</span></code>.</p>
<p>Type <code class="docutils literal notranslate"><span class="pre">?factor</span></code> in the console for more information.</p>
</div></blockquote>
<p>To answer the question above we will convert <em>categorical</em> variables to <code class="docutils literal notranslate"><span class="pre">numeric</span></code> one.</p>
</div>
<div class="section" id="conversion-from-categorical-to-numeric-variables">
<span id="conversion-from-categorical-to-numeric-variables"></span><h3>Conversion from categorical to numeric variables<a class="headerlink" href="#conversion-from-categorical-to-numeric-variables" title="Permalink to this headline">¶</a></h3>
<div class="section" id="looking-at-the-raw-data">
<span id="looking-at-the-raw-data"></span><h4>Looking at the raw data<a class="headerlink" href="#looking-at-the-raw-data" title="Permalink to this headline">¶</a></h4>
<p>In this Vignette we will see how to transform a <em>dense</em> <code class="docutils literal notranslate"><span class="pre">data.frame</span></code> (<em>dense</em> = few zeroes in the matrix) with <em>categorical</em> variables to a very <em>sparse</em> matrix (<em>sparse</em> = lots of zero in the matrix) of <code class="docutils literal notranslate"><span class="pre">numeric</span></code> features.</p>
<p>The method we are going to see is usually called <a class="reference external" href="http://en.wikipedia.org/wiki/One-hot">one-hot encoding</a>.</p>
<p>The first step is to load <code class="docutils literal notranslate"><span class="pre">Arthritis</span></code> dataset in memory and wrap it with <code class="docutils literal notranslate"><span class="pre">data.table</span></code> package.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>data<span class="p">(</span>Arthritis<span class="p">)</span>
df <span class="o">&lt;-</span> data.table<span class="p">(</span>Arthritis<span class="p">,</span> keep.rownames <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><code class="docutils literal notranslate"><span class="pre">data.table</span></code> is 100% compliant with <strong>R</strong> <code class="docutils literal notranslate"><span class="pre">data.frame</span></code> but its syntax is more consistent and its performance for large dataset is <a class="reference external" href="http://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly">best in class</a> (<code class="docutils literal notranslate"><span class="pre">dplyr</span></code> from <strong>R</strong> and <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> from <strong>Python</strong> <a class="reference external" href="https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping">included</a>). Some parts of <strong>Xgboost</strong> <strong>R</strong> package use <code class="docutils literal notranslate"><span class="pre">data.table</span></code>.</div></blockquote>
<p>The first thing we want to do is to have a look to the first lines of the <code class="docutils literal notranslate"><span class="pre">data.table</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kp">head</span><span class="p">(</span>df<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##    ID Treatment  Sex Age Improved</span>
<span class="c1">## 1: 57   Treated Male  27     Some</span>
<span class="c1">## 2: 46   Treated Male  29     None</span>
<span class="c1">## 3: 77   Treated Male  30     None</span>
<span class="c1">## 4: 17   Treated Male  32   Marked</span>
<span class="c1">## 5: 36   Treated Male  46   Marked</span>
<span class="c1">## 6: 23   Treated Male  58   Marked</span>
</pre></div>
</div>
<p>Now we will check the format of each column.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>str<span class="p">(</span>df<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   84 obs. of  5 variables:</span>
<span class="c1">##  $ ID       : int  57 46 77 17 36 23 75 39 33 55 ...</span>
<span class="c1">##  $ Treatment: Factor w/ 2 levels &quot;Placebo&quot;,&quot;Treated&quot;: 2 2 2 2 2 2 2 2 2 2 ...</span>
<span class="c1">##  $ Sex      : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 2 2 2 2 2 2 2 2 2 2 ...</span>
<span class="c1">##  $ Age      : int  27 29 30 32 46 58 59 59 63 63 ...</span>
<span class="c1">##  $ Improved : Ord.factor w/ 3 levels &quot;None&quot;&lt;&quot;Some&quot;&lt;..: 2 1 1 3 3 3 1 3 1 1 ...</span>
<span class="c1">##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;</span>
</pre></div>
</div>
<p>2 columns have <code class="docutils literal notranslate"><span class="pre">factor</span></code> type, one has <code class="docutils literal notranslate"><span class="pre">ordinal</span></code> type.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">ordinal</span></code> variable :</p>
<ul class="simple">
<li>can take a limited number of values (like <code class="docutils literal notranslate"><span class="pre">factor</span></code>) ;</li>
<li>these values are ordered (unlike <code class="docutils literal notranslate"><span class="pre">factor</span></code>). Here these ordered values are: <code class="docutils literal notranslate"><span class="pre">Marked</span> <span class="pre">&gt;</span> <span class="pre">Some</span> <span class="pre">&gt;</span> <span class="pre">None</span></code></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="creation-of-new-features-based-on-old-ones">
<span id="creation-of-new-features-based-on-old-ones"></span><h4>Creation of new features based on old ones<a class="headerlink" href="#creation-of-new-features-based-on-old-ones" title="Permalink to this headline">¶</a></h4>
<p>We will add some new <em>categorical</em> features to see if it helps.</p>
<div class="section" id="grouping-per-10-years">
<span id="grouping-per-10-years"></span><h5>Grouping per 10 years<a class="headerlink" href="#grouping-per-10-years" title="Permalink to this headline">¶</a></h5>
<p>For the first feature we create groups of age by rounding the real age.</p>
<p>Note that we transform it to <code class="docutils literal notranslate"><span class="pre">factor</span></code> so the algorithm treat these age groups as independent values.</p>
<p>Therefore, 20 is not closer to 30 than 60. To make it short, the distance between ages is lost in this transformation.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kp">head</span><span class="p">(</span>df<span class="p">[,</span>AgeDiscret <span class="o">:=</span> <span class="kp">as.factor</span><span class="p">(</span><span class="kp">round</span><span class="p">(</span>Age<span class="o">/</span><span class="m">10</span><span class="p">,</span><span class="m">0</span><span class="p">))])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##    ID Treatment  Sex Age Improved AgeDiscret</span>
<span class="c1">## 1: 57   Treated Male  27     Some          3</span>
<span class="c1">## 2: 46   Treated Male  29     None          3</span>
<span class="c1">## 3: 77   Treated Male  30     None          3</span>
<span class="c1">## 4: 17   Treated Male  32   Marked          3</span>
<span class="c1">## 5: 36   Treated Male  46   Marked          5</span>
<span class="c1">## 6: 23   Treated Male  58   Marked          6</span>
</pre></div>
</div>
</div>
<div class="section" id="random-split-in-two-groups">
<span id="random-split-in-two-groups"></span><h5>Random split in two groups<a class="headerlink" href="#random-split-in-two-groups" title="Permalink to this headline">¶</a></h5>
<p>Following is an even stronger simplification of the real age with an arbitrary split at 30 years old. I choose this value <strong>based on nothing</strong>. We will see later if simplifying the information based on arbitrary values is a good strategy (you may already have an idea of how well it will work…).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kp">head</span><span class="p">(</span>df<span class="p">[,</span>AgeCat<span class="o">:=</span> <span class="kp">as.factor</span><span class="p">(</span><span class="kp">ifelse</span><span class="p">(</span>Age <span class="o">&gt;</span> <span class="m">30</span><span class="p">,</span> <span class="s">&quot;Old&quot;</span><span class="p">,</span> <span class="s">&quot;Young&quot;</span><span class="p">))])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##    ID Treatment  Sex Age Improved AgeDiscret AgeCat</span>
<span class="c1">## 1: 57   Treated Male  27     Some          3  Young</span>
<span class="c1">## 2: 46   Treated Male  29     None          3  Young</span>
<span class="c1">## 3: 77   Treated Male  30     None          3  Young</span>
<span class="c1">## 4: 17   Treated Male  32   Marked          3    Old</span>
<span class="c1">## 5: 36   Treated Male  46   Marked          5    Old</span>
<span class="c1">## 6: 23   Treated Male  58   Marked          6    Old</span>
</pre></div>
</div>
</div>
<div class="section" id="risks-in-adding-correlated-features">
<span id="risks-in-adding-correlated-features"></span><h5>Risks in adding correlated features<a class="headerlink" href="#risks-in-adding-correlated-features" title="Permalink to this headline">¶</a></h5>
<p>These new features are highly correlated to the <code class="docutils literal notranslate"><span class="pre">Age</span></code> feature because they are simple transformations of this feature.</p>
<p>For many machine learning algorithms, using correlated features is not a good idea. It may sometimes make prediction less accurate, and most of the time make interpretation of the model almost impossible. GLM, for instance, assumes that the features are uncorrelated.</p>
<p>Fortunately, decision tree algorithms (including boosted trees) are very robust to these features. Therefore we have nothing to do to manage this situation.</p>
</div>
<div class="section" id="cleaning-data">
<span id="cleaning-data"></span><h5>Cleaning data<a class="headerlink" href="#cleaning-data" title="Permalink to this headline">¶</a></h5>
<p>We remove ID as there is nothing to learn from this feature (it would just add some noise).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>df<span class="p">[,</span>ID<span class="o">:=</span><span class="kc">NULL</span><span class="p">]</span>
</pre></div>
</div>
<p>We will list the different values for the column <code class="docutils literal notranslate"><span class="pre">Treatment</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="kp">levels</span><span class="p">(</span>df<span class="p">[,</span>Treatment<span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [1] &quot;Placebo&quot; &quot;Treated&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="one-hot-encoding">
<span id="one-hot-encoding"></span><h4>One-hot encoding<a class="headerlink" href="#one-hot-encoding" title="Permalink to this headline">¶</a></h4>
<p>Next step, we will transform the categorical data to dummy variables.
This is the <a class="reference external" href="http://en.wikipedia.org/wiki/One-hot">one-hot encoding</a> step.</p>
<p>The purpose is to transform each value of each <em>categorical</em> feature in a <em>binary</em> feature <code class="docutils literal notranslate"><span class="pre">{0,</span> <span class="pre">1}</span></code>.</p>
<p>For example, the column <code class="docutils literal notranslate"><span class="pre">Treatment</span></code> will be replaced by two columns, <code class="docutils literal notranslate"><span class="pre">Placebo</span></code>, and <code class="docutils literal notranslate"><span class="pre">Treated</span></code>. Each of them will be <em>binary</em>. Therefore, an observation which has the value <code class="docutils literal notranslate"><span class="pre">Placebo</span></code> in column <code class="docutils literal notranslate"><span class="pre">Treatment</span></code> before the transformation will have after the transformation the value <code class="docutils literal notranslate"><span class="pre">1</span></code> in the new column <code class="docutils literal notranslate"><span class="pre">Placebo</span></code> and the value <code class="docutils literal notranslate"><span class="pre">0</span></code> in the new column <code class="docutils literal notranslate"><span class="pre">Treated</span></code>. The column <code class="docutils literal notranslate"><span class="pre">Treatment</span></code> will disappear during the one-hot encoding.</p>
<p>Column <code class="docutils literal notranslate"><span class="pre">Improved</span></code> is excluded because it will be our <code class="docutils literal notranslate"><span class="pre">label</span></code> column, the one we want to predict.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>sparse_matrix <span class="o">&lt;-</span> sparse.model.matrix<span class="p">(</span>Improved<span class="o">~</span><span class="m">.-1</span><span class="p">,</span> data <span class="o">=</span> df<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>sparse_matrix<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## 6 x 10 sparse Matrix of class &quot;dgCMatrix&quot;</span>
<span class="c1">##                       </span>
<span class="c1">## 1 . 1 1 27 1 . . . . 1</span>
<span class="c1">## 2 . 1 1 29 1 . . . . 1</span>
<span class="c1">## 3 . 1 1 30 1 . . . . 1</span>
<span class="c1">## 4 . 1 1 32 1 . . . . .</span>
<span class="c1">## 5 . 1 1 46 . . 1 . . .</span>
<span class="c1">## 6 . 1 1 58 . . . 1 . .</span>
</pre></div>
</div>
<blockquote>
<div>Formulae <code class="docutils literal notranslate"><span class="pre">Improved~.-1</span></code> used above means transform all <em>categorical</em> features but column <code class="docutils literal notranslate"><span class="pre">Improved</span></code> to binary values. The <code class="docutils literal notranslate"><span class="pre">-1</span></code> is here to remove the first column which is full of <code class="docutils literal notranslate"><span class="pre">1</span></code> (this column is generated by the conversion). For more information, you can type <code class="docutils literal notranslate"><span class="pre">?sparse.model.matrix</span></code> in the console.</div></blockquote>
<p>Create the output <code class="docutils literal notranslate"><span class="pre">numeric</span></code> vector (not as a sparse <code class="docutils literal notranslate"><span class="pre">Matrix</span></code>):</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>output_vector <span class="o">=</span> df<span class="p">[,</span>Improved<span class="p">]</span> <span class="o">==</span> <span class="s">&quot;Marked&quot;</span>
</pre></div>
</div>
<ol class="simple">
<li>set <code class="docutils literal notranslate"><span class="pre">Y</span></code> vector to <code class="docutils literal notranslate"><span class="pre">0</span></code>;</li>
<li>set <code class="docutils literal notranslate"><span class="pre">Y</span></code> to <code class="docutils literal notranslate"><span class="pre">1</span></code> for rows where <code class="docutils literal notranslate"><span class="pre">Improved</span> <span class="pre">==</span> <span class="pre">Marked</span></code> is <code class="docutils literal notranslate"><span class="pre">TRUE</span></code> ;</li>
<li>return <code class="docutils literal notranslate"><span class="pre">Y</span></code> vector.</li>
</ol>
</div>
</div>
</div>
<div class="section" id="build-the-model">
<span id="build-the-model"></span><h2>Build the model<a class="headerlink" href="#build-the-model" title="Permalink to this headline">¶</a></h2>
<p>The code below is very usual. For more information, you can look at the documentation of <code class="docutils literal notranslate"><span class="pre">xgboost</span></code> function (or at the vignette <a class="reference external" href="https://github.com/dmlc/xgboost/blob/master/R-package/vignettes/xgboostPresentation.Rmd">Xgboost presentation</a>).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>bst <span class="o">&lt;-</span> xgboost<span class="p">(</span>data <span class="o">=</span> sparse_matrix<span class="p">,</span> label <span class="o">=</span> output_vector<span class="p">,</span> max.depth <span class="o">=</span> <span class="m">4</span><span class="p">,</span>
               eta <span class="o">=</span> <span class="m">1</span><span class="p">,</span> nthread <span class="o">=</span> <span class="m">2</span><span class="p">,</span> nrounds <span class="o">=</span> <span class="m">10</span><span class="p">,</span>objective <span class="o">=</span> <span class="s">&quot;binary:logistic&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [0]  train-error:0.202381</span>
<span class="c1">## [1]  train-error:0.166667</span>
<span class="c1">## [2]  train-error:0.166667</span>
<span class="c1">## [3]  train-error:0.166667</span>
<span class="c1">## [4]  train-error:0.154762</span>
<span class="c1">## [5]  train-error:0.154762</span>
<span class="c1">## [6]  train-error:0.154762</span>
<span class="c1">## [7]  train-error:0.166667</span>
<span class="c1">## [8]  train-error:0.166667</span>
<span class="c1">## [9]  train-error:0.166667</span>
</pre></div>
</div>
<p>You can see some <code class="docutils literal notranslate"><span class="pre">train-error:</span> <span class="pre">0.XXXXX</span></code> lines followed by a number. It decreases. Each line shows how well the model explains your data. Lower is better.</p>
<p>A model which fits too well may <a class="reference external" href="http://en.wikipedia.org/wiki/Overfitting">overfit</a> (meaning it copy/paste too much the past, and won’t be that good to predict the future).</p>
<blockquote>
<div><p>Here you can see the numbers decrease until line 7 and then increase.</p>
<p>It probably means we are overfitting. To fix that I should reduce the number of rounds to <code class="docutils literal notranslate"><span class="pre">nrounds</span> <span class="pre">=</span> <span class="pre">4</span></code>. I will let things like that because I don’t really care for the purpose of this example :-)</p>
</div></blockquote>
</div>
<div class="section" id="feature-importance">
<span id="feature-importance"></span><h2>Feature importance<a class="headerlink" href="#feature-importance" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="measure-feature-importance">
<span id="measure-feature-importance"></span><h2>Measure feature importance<a class="headerlink" href="#measure-feature-importance" title="Permalink to this headline">¶</a></h2>
<div class="section" id="build-the-feature-importance-data-table">
<span id="build-the-feature-importance-data-table"></span><h3>Build the feature importance data.table<a class="headerlink" href="#build-the-feature-importance-data-table" title="Permalink to this headline">¶</a></h3>
<p>In the code below, <code class="docutils literal notranslate"><span class="pre">sparse_matrix&#64;Dimnames[[2]]</span></code> represents the column names of the sparse matrix. These names are the original values of the features (remember, each binary column == one value of one <em>categorical</em> feature).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>importance <span class="o">&lt;-</span> xgb.importance<span class="p">(</span>feature_names <span class="o">=</span> sparse_matrix<span class="o">@</span>Dimnames<span class="p">[[</span><span class="m">2</span><span class="p">]],</span> model <span class="o">=</span> bst<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>importance<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##             Feature        Gain      Cover  Frequency</span>
<span class="c1">## 1:              Age 0.622031651 0.67251706 0.67241379</span>
<span class="c1">## 2: TreatmentPlacebo 0.285750607 0.11916656 0.10344828</span>
<span class="c1">## 3:          SexMale 0.048744054 0.04522027 0.08620690</span>
<span class="c1">## 4:      AgeDiscret6 0.016604647 0.04784637 0.05172414</span>
<span class="c1">## 5:      AgeDiscret3 0.016373791 0.08028939 0.05172414</span>
<span class="c1">## 6:      AgeDiscret4 0.009270558 0.02858801 0.01724138</span>
</pre></div>
</div>
<blockquote>
<div><p>The column <code class="docutils literal notranslate"><span class="pre">Gain</span></code> provide the information we are looking for.</p>
<p>As you can see, features are classified by <code class="docutils literal notranslate"><span class="pre">Gain</span></code>.</p>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">Gain</span></code> is the improvement in accuracy brought by a feature to the branches it is on. The idea is that before adding a new split on a feature X to the branch there was some wrongly classified elements, after adding the split on this feature, there are two new branches, and each of these branch is more accurate (one branch saying if your observation is on this branch then it should be classified as <code class="docutils literal notranslate"><span class="pre">1</span></code>, and the other branch saying the exact opposite).</p>
<p><code class="docutils literal notranslate"><span class="pre">Cover</span></code> measures the relative quantity of observations concerned by a feature.</p>
<p><code class="docutils literal notranslate"><span class="pre">Frequency</span></code> is a simpler way to measure the <code class="docutils literal notranslate"><span class="pre">Gain</span></code>. It just counts the number of times a feature is used in all generated trees. You should not use it (unless you know why you want to use it).</p>
<div class="section" id="improvement-in-the-interpretability-of-feature-importance-data-table">
<span id="improvement-in-the-interpretability-of-feature-importance-data-table"></span><h4>Improvement in the interpretability of feature importance data.table<a class="headerlink" href="#improvement-in-the-interpretability-of-feature-importance-data-table" title="Permalink to this headline">¶</a></h4>
<p>We can go deeper in the analysis of the model. In the <code class="docutils literal notranslate"><span class="pre">data.table</span></code> above, we have discovered which features counts to predict if the illness will go or not. But we don’t yet know the role of these features. For instance, one of the question we may want to answer would be: does receiving a placebo treatment helps to recover from the illness?</p>
<p>One simple solution is to count the co-occurrences of a feature and a class of the classification.</p>
<p>For that purpose we will execute the same function as above but using two more parameters, <code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">label</span></code>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>importanceRaw <span class="o">&lt;-</span> xgb.importance<span class="p">(</span>feature_names <span class="o">=</span> sparse_matrix<span class="o">@</span>Dimnames<span class="p">[[</span><span class="m">2</span><span class="p">]],</span> model <span class="o">=</span> bst<span class="p">,</span> data <span class="o">=</span> sparse_matrix<span class="p">,</span> label <span class="o">=</span> output_vector<span class="p">)</span>

<span class="c1"># Cleaning for better display</span>
importanceClean <span class="o">&lt;-</span> importanceRaw<span class="p">[,</span><span class="sb">`:=`</span><span class="p">(</span>Cover<span class="o">=</span><span class="kc">NULL</span><span class="p">,</span> Frequency<span class="o">=</span><span class="kc">NULL</span><span class="p">)]</span>

<span class="kp">head</span><span class="p">(</span>importanceClean<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##             Feature        Split       Gain RealCover RealCover %</span>
<span class="c1">## 1: TreatmentPlacebo -1.00136e-05 0.28575061         7   0.2500000</span>
<span class="c1">## 2:              Age         61.5 0.16374034        12   0.4285714</span>
<span class="c1">## 3:              Age           39 0.08705750         8   0.2857143</span>
<span class="c1">## 4:              Age         57.5 0.06947553        11   0.3928571</span>
<span class="c1">## 5:          SexMale -1.00136e-05 0.04874405         4   0.1428571</span>
<span class="c1">## 6:              Age         53.5 0.04620627        10   0.3571429</span>
</pre></div>
</div>
<blockquote>
<div>In the table above we have removed two not needed columns and select only the first lines.</div></blockquote>
<p>First thing you notice is the new column <code class="docutils literal notranslate"><span class="pre">Split</span></code>. It is the split applied to the feature on a branch of one of the tree. Each split is present, therefore a feature can appear several times in this table. Here we can see the feature <code class="docutils literal notranslate"><span class="pre">Age</span></code> is used several times with different splits.</p>
<p>How the split is applied to count the co-occurrences? It is always <code class="docutils literal notranslate"><span class="pre">&lt;</span></code>. For instance, in the second line, we measure the number of persons under 61.5 years with the illness gone after the treatment.</p>
<p>The two other new columns are <code class="docutils literal notranslate"><span class="pre">RealCover</span></code> and <code class="docutils literal notranslate"><span class="pre">RealCover</span> <span class="pre">%</span></code>. In the first column it measures the number of observations in the dataset where the split is respected and the label marked as <code class="docutils literal notranslate"><span class="pre">1</span></code>. The second column is the percentage of the whole population that <code class="docutils literal notranslate"><span class="pre">RealCover</span></code> represents.</p>
<p>Therefore, according to our findings, getting a placebo doesn’t seem to help but being younger than 61 years may help (seems logic).</p>
<blockquote>
<div>You may wonder how to interpret the <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">1.00001</span></code> on the first line. Basically, in a sparse <code class="docutils literal notranslate"><span class="pre">Matrix</span></code>, there is no <code class="docutils literal notranslate"><span class="pre">0</span></code>, therefore, looking for one hot-encoded categorical observations validating the rule <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">1.00001</span></code> is like just looking for <code class="docutils literal notranslate"><span class="pre">1</span></code> for this feature.</div></blockquote>
</div>
</div>
<div class="section" id="plotting-the-feature-importance">
<span id="plotting-the-feature-importance"></span><h3>Plotting the feature importance<a class="headerlink" href="#plotting-the-feature-importance" title="Permalink to this headline">¶</a></h3>
<p>All these things are nice, but it would be even better to plot the results.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>xgb.plot.importance<span class="p">(</span>importance_matrix <span class="o">=</span> importanceRaw<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Error in xgb.plot.importance(importance_matrix = importanceRaw): Importance matrix is not correct (column names issue)</span>
</pre></div>
</div>
<p>Feature have automatically been divided in 2 clusters: the interesting features… and the others.</p>
<blockquote>
<div>Depending of the dataset and the learning parameters you may have more than two clusters. Default value is to limit them to <code class="docutils literal notranslate"><span class="pre">10</span></code>, but you can increase this limit. Look at the function documentation for more information.</div></blockquote>
<p>According to the plot above, the most important features in this dataset to predict if the treatment will work are :</p>
<ul class="simple">
<li>the Age ;</li>
<li>having received a placebo or not ;</li>
<li>the sex is third but already included in the not interesting features group ;</li>
<li>then we see our generated features (AgeDiscret). We can see that their contribution is very low.</li>
</ul>
</div>
<div class="section" id="do-these-results-make-sense">
<span id="do-these-results-make-sense"></span><h3>Do these results make sense?<a class="headerlink" href="#do-these-results-make-sense" title="Permalink to this headline">¶</a></h3>
<p>Let’s check some <strong>Chi2</strong> between each of these features and the label.</p>
<p>Higher <strong>Chi2</strong> means better correlation.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>c2 <span class="o">&lt;-</span> chisq.test<span class="p">(</span>df<span class="o">$</span>Age<span class="p">,</span> output_vector<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span>c2<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## </span>
<span class="c1">##  Pearson&#39;s Chi-squared test</span>
<span class="c1">## </span>
<span class="c1">## data:  df$Age and output_vector</span>
<span class="c1">## X-squared = 35.475, df = 35, p-value = 0.4458</span>
</pre></div>
</div>
<p>Pearson correlation between Age and illness disappearing is <strong>35.48</strong>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>c2 <span class="o">&lt;-</span> chisq.test<span class="p">(</span>df<span class="o">$</span>AgeDiscret<span class="p">,</span> output_vector<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span>c2<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## </span>
<span class="c1">##  Pearson&#39;s Chi-squared test</span>
<span class="c1">## </span>
<span class="c1">## data:  df$AgeDiscret and output_vector</span>
<span class="c1">## X-squared = 8.2554, df = 5, p-value = 0.1427</span>
</pre></div>
</div>
<p>Our first simplification of Age gives a Pearson correlation is <strong>8.26</strong>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>c2 <span class="o">&lt;-</span> chisq.test<span class="p">(</span>df<span class="o">$</span>AgeCat<span class="p">,</span> output_vector<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span>c2<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## </span>
<span class="c1">##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction</span>
<span class="c1">## </span>
<span class="c1">## data:  df$AgeCat and output_vector</span>
<span class="c1">## X-squared = 2.3571, df = 1, p-value = 0.1247</span>
</pre></div>
</div>
<p>The perfectly random split I did between young and old at 30 years old have a low correlation of <strong>2.36</strong>. It’s a result we may expect as may be in my mind &gt; 30 years is being old (I am 32 and starting feeling old, this may explain that), but for the illness we are studying, the age to be vulnerable is not the same.</p>
<p>Morality: don’t let your <em>gut</em> lower the quality of your model.</p>
<p>In <em>data science</em> expression, there is the word <em>science</em> :-)</p>
</div>
</div>
<div class="section" id="conclusion">
<span id="conclusion"></span><h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>As you can see, in general <em>destroying information by simplifying it won’t improve your model</em>. <strong>Chi2</strong> just demonstrates that.</p>
<p>But in more complex cases, creating a new feature based on existing one which makes link with the outcome more obvious may help the algorithm and improve the model.</p>
<p>The case studied here is not enough complex to show that. Check <a class="reference external" href="http://www.kaggle.com/">Kaggle website</a> for some challenging datasets. However it’s almost always worse when you add some arbitrary rules.</p>
<p>Moreover, you can notice that even if we have added some not useful new features highly correlated with other features, the boosting tree algorithm have been able to choose the best one, which in this case is the Age.</p>
<p>Linear models may not be that smart in this scenario.</p>
</div>
<div class="section" id="special-note-what-about-random-forests">
<span id="special-note-what-about-random-forests"></span><h2>Special Note: What about Random Forests™?<a class="headerlink" href="#special-note-what-about-random-forests" title="Permalink to this headline">¶</a></h2>
<p>As you may know, <a class="reference external" href="http://en.wikipedia.org/wiki/Random_forest">Random Forests™</a> algorithm is cousin with boosting and both are part of the <a class="reference external" href="http://en.wikipedia.org/wiki/Ensemble_learning">ensemble learning</a> family.</p>
<p>Both train several decision trees for one dataset. The <em>main</em> difference is that in Random Forests™, trees are independent and in boosting, the tree <code class="docutils literal notranslate"><span class="pre">N+1</span></code> focus its learning on the loss (&lt;=&gt; what has not been well modeled by the tree <code class="docutils literal notranslate"><span class="pre">N</span></code>).</p>
<p>This difference have an impact on a corner case in feature importance analysis: the <em>correlated features</em>.</p>
<p>Imagine two features perfectly correlated, feature <code class="docutils literal notranslate"><span class="pre">A</span></code> and feature <code class="docutils literal notranslate"><span class="pre">B</span></code>. For one specific tree, if the algorithm needs one of them, it will choose randomly (true in both boosting and Random Forests™).</p>
<p>However, in Random Forests™ this random choice will be done for each tree, because each tree is independent from the others. Therefore, approximatively, depending of your parameters, 50% of the trees will choose feature <code class="docutils literal notranslate"><span class="pre">A</span></code> and the other 50% will choose feature <code class="docutils literal notranslate"><span class="pre">B</span></code>. So the <em>importance</em> of the information contained in <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> (which is the same, because they are perfectly correlated) is diluted in <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code>. So you won’t easily know this information is important to predict what you want to predict! It is even worse when you have 10 correlated features…</p>
<p>In boosting, when a specific link between feature and outcome have been learned by the algorithm, it will try to not refocus on it (in theory it is what happens, reality is not always that simple). Therefore, all the importance will be on feature <code class="docutils literal notranslate"><span class="pre">A</span></code> or on feature <code class="docutils literal notranslate"><span class="pre">B</span></code> (but not both). You will know that one feature have an important role in the link between the observations and the label. It is still up to you to search for the correlated features to the one detected as important if you need to know all of them.</p>
<p>If you want to try Random Forests™ algorithm, you can tweak Xgboost parameters!</p>
<p><strong>Warning</strong>: this is still an experimental parameter.</p>
<p>For instance, to compute a model with 1000 trees, with a 0.5 factor on sampling rows and columns:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>data<span class="p">(</span>agaricus.train<span class="p">,</span> package<span class="o">=</span><span class="s">&#39;xgboost&#39;</span><span class="p">)</span>
data<span class="p">(</span>agaricus.test<span class="p">,</span> package<span class="o">=</span><span class="s">&#39;xgboost&#39;</span><span class="p">)</span>
train <span class="o">&lt;-</span> agaricus.train
test <span class="o">&lt;-</span> agaricus.test

<span class="c1">#Random Forest™ - 1000 trees</span>
bst <span class="o">&lt;-</span> xgboost<span class="p">(</span>data <span class="o">=</span> train<span class="o">$</span>data<span class="p">,</span> label <span class="o">=</span> train<span class="o">$</span>label<span class="p">,</span> max.depth <span class="o">=</span> <span class="m">4</span><span class="p">,</span> num_parallel_tree <span class="o">=</span> <span class="m">1000</span><span class="p">,</span> subsample <span class="o">=</span> <span class="m">0.5</span><span class="p">,</span> colsample_bytree <span class="o">=</span><span class="m">0.5</span><span class="p">,</span> nrounds <span class="o">=</span> <span class="m">1</span><span class="p">,</span> objective <span class="o">=</span> <span class="s">&quot;binary:logistic&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [0]  train-error:0.002150</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#Boosting - 3 rounds</span>
bst <span class="o">&lt;-</span> xgboost<span class="p">(</span>data <span class="o">=</span> train<span class="o">$</span>data<span class="p">,</span> label <span class="o">=</span> train<span class="o">$</span>label<span class="p">,</span> max.depth <span class="o">=</span> <span class="m">4</span><span class="p">,</span> nrounds <span class="o">=</span> <span class="m">3</span><span class="p">,</span> objective <span class="o">=</span> <span class="s">&quot;binary:logistic&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## [0]  train-error:0.006142</span>
<span class="c1">## [1]  train-error:0.006756</span>
<span class="c1">## [2]  train-error:0.001228</span>
</pre></div>
</div>
<blockquote>
<div>Note that the parameter <code class="docutils literal notranslate"><span class="pre">round</span></code> is set to <code class="docutils literal notranslate"><span class="pre">1</span></code>.</div></blockquote>
<blockquote>
<div><a class="reference external" href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_papers.htm"><strong>Random Forests™</strong></a> is a trademark of Leo Breiman and Adele Cutler and is licensed exclusively to Salford Systems for the commercial release of the software.</div></blockquote>
</div>
</div>


          </div>
            
  <div class="footer-relations">
    
      <div class="pull-left">
        <a class="btn btn-default" href="xgboostPresentation.html" title="previous chapter (use the left arrow)">XGBoost R Tutorial</a>
      </div>
    
      <div class="pull-right">
        <a class="btn btn-default" href="../jvm/index.html" title="next chapter (use the right arrow)">XGBoost JVM Package</a>
      </div>
    </div>
    <div class="clearer"></div>
  
        </div>
        <div class="clearfix"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../jvm/index.html" title="XGBoost JVM Package"
             >next</a> |</li>
        <li class="right" >
          <a href="xgboostPresentation.html" title="XGBoost R Tutorial"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">xgboost 0.80 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >XGBoost R Package</a> &#187;</li> 
      </ul>
    </div>
<script type="text/javascript">
  $("#mobile-toggle a").click(function () {
    $("#left-column").toggle();
  });
</script>
<script type="text/javascript" src="../_static/js/bootstrap.js"></script>
  <div class="footer">
    &copy; Copyright 2016, xgboost developers. Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  </body>
</html>